{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "from urllib.parse import urlparse\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "from radam import RAdam\n",
    "from text_data import TextDataset3\n",
    "from bert import CustomBert6\n",
    "from learning import Learner\n",
    "from lr_finder import LRFinder\n",
    "from one_cycle import OneCycleLR\n",
    "from text_cleaning import clean_data\n",
    "from sentence_embed import get_use_embedding_features, get_distill_bert_features\n",
    "from create_features import get_dist_features, get_categorical_features\n",
    "from losses_metrics import spearmanr_torch, spearmanr_np\n",
    "from inference import infer\n",
    "from eda import eda\n",
    "from common import *\n",
    "from utils.helpers import init_logger, init_seed\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "path = 'data/'\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
    "test = pd.read_csv(f'{path}test.csv').fillna(' ')\n",
    "train = pd.read_csv(f'{path}train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aug = 4\n",
    "train_aug_dfs = [train.copy() for _ in range(num_aug)]\n",
    "test_aug_dfs = [test.copy() for _ in range(num_aug)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer.encode_plus(' \\n \\n \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "ids_train = {}\n",
    "ids_test = {}\n",
    "max_seq_len = 512\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text in ['question', 'answer']:\n",
    "        ids = (num_aug + 1) * []\n",
    "        for x in tqdm(df[text].values):\n",
    "            augs = eda(x, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=num_aug)\n",
    "            encoded_inputs = []\n",
    "            for i, aug in enumerate(augs):\n",
    "                encoded_inputs = tokenizer.encode_plus(\n",
    "                    x, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)['input_ids']\n",
    "                ids[i].append(encoded_inputs)\n",
    "        if mode == 'train': ids_train[text] = [np.array(aug_ids) for aug_ids in ids]\n",
    "        else: ids_test[text]  = [np.array(aug_ids) for aug_ids in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what am i losing when using tubes instead of a macro lens',\n",
       " 'macro instruction what am i losing when using extension tubes instead of a macro lens',\n",
       " 'what am i losing when using extension thermionic valve instead of a macro lens',\n",
       " 'what am i losing when of extension tubes instead using a macro lens',\n",
       " 'what am i losing when using extension tubes instead of a macro lens']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda(train['question_title'].values[0], alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question'] = train['question_title'] + ' [SEP] ' + train['question_body']\n",
    "test['question'] = test['question_title'] + ' [SEP] ' + test['question_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6079/6079 [00:12<00:00, 485.47it/s]\n",
      "100%|██████████| 6079/6079 [00:11<00:00, 535.54it/s]\n",
      "100%|██████████| 476/476 [00:00<00:00, 495.86it/s]\n",
      "100%|██████████| 476/476 [00:00<00:00, 491.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.2 s, sys: 169 ms, total: 26.4 s\n",
      "Wall time: 26.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "ids_train = {}\n",
    "ids_test = {}\n",
    "max_seq_len = 512\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text in ['question', 'answer']:\n",
    "        ids = []\n",
    "        for x in tqdm(df[text].values):\n",
    "            encoded_inputs = tokenizer.encode_plus(\n",
    "                x, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)\n",
    "            ids.append(encoded_inputs['input_ids'])\n",
    "        if mode == 'train': ids_train[text] = np.array(ids)\n",
    "        else: ids_test[text] = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_host, test_host, host_dict, host_dict_reverse = get_categorical_features(train, test, 'host')\n",
    "train_category, test_category, category_dict, category_dict_reverse = \\\n",
    "    get_categorical_features(train, test, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_features_train = np.hstack([train_host.reshape(-1, 1), train_category.reshape(-1, 1)])\n",
    "cat_features_test = np.hstack([test_host.reshape(-1, 1), test_category.reshape(-1, 1)])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(cat_features_train)\n",
    "\n",
    "cat_features_train = ohe.transform(cat_features_train).toarray()\n",
    "cat_features_test = ohe.transform(cat_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[TARGETS].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_test = 4\n",
    "test_loader = DataLoader(\n",
    "    TextDataset3(cat_features_test, ids_test['question'], ids_test['answer'], test.index),\n",
    "    batch_size=bs_test, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = 'cuda'\n",
    "n_epochs = 6\n",
    "grad_accum = 8\n",
    "weight_decay = 0.01\n",
    "model_name = 'distil_bert_2'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_param_groups(model, lr, weight_decay):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': weight_decay, 'lr': lr},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0, 'lr': lr}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "lr_div = 100\n",
    "def get_optimizer(model, lr, weight_decay):\n",
    "    return transformers.AdamW(\n",
    "        get_optimizer_param_groups(model.head, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.transformer, lr / lr_div, weight_decay)\n",
    "        + get_optimizer_param_groups(model.q_transformer, lr / lr_div, weight_decay)\n",
    "        + get_optimizer_param_groups(model.a_transformer, lr / lr_div, weight_decay)\n",
    "        + get_optimizer_param_groups(model.q_emb, lr / lr_div, weight_decay)\n",
    "        + get_optimizer_param_groups(model.a_emb, lr / lr_div, weight_decay)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     6
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Tue Dec 24 21:51:48 2019\n",
      "CustomBert6(\n",
      "  (q_emb): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (a_emb): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (q_transformer): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (a_transformer): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (transformer): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (head): HeadNet2(\n",
      "    (lin): Sequential(\n",
      "      (0): Linear(in_features=1604, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_q): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_a): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (head_q): Linear(in_features=512, out_features=21, bias=True)\n",
      "    (head_a): Linear(in_features=512, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee574fd1aa634143b1f2f52011bdfd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd73feb9d60459286f33402607ffe3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/6 \t train : loss 0.47926 - spearmanr 0.090826\n",
      "epoch 0: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b28124dcef4c6a97dc9a2859637f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/6 \t valid : loss 0.40256 - spearmanr 0.27068\n",
      "best model: epoch 0 - 0.27068\n",
      "epoch 1: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7e950fd50847a0bdcd773a34b2e835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/6 \t train : loss 0.39023 - spearmanr 0.29029\n",
      "epoch 1: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f25f3b5d9d4aa8adaf276d66df5a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/6 \t valid : loss 0.38194 - spearmanr 0.34782\n",
      "best model: epoch 1 - 0.34782\n",
      "epoch 2: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5730263972a7497bb3e1462abbbe444d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/6 \t train : loss 0.37102 - spearmanr 0.36805\n",
      "epoch 2: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4db6bc1f7a4ec3b7f2fb228032be37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/6 \t valid : loss 0.37338 - spearmanr 0.3826\n",
      "best model: epoch 2 - 0.3826\n",
      "epoch 3: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da87af76edb54c4dbc032c2a12afd6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3/6 \t train : loss 0.36032 - spearmanr 0.40875\n",
      "epoch 3: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024ba6541f814f74a2962f9c475816ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3/6 \t valid : loss 0.37046 - spearmanr 0.39273\n",
      "best model: epoch 3 - 0.39273\n",
      "epoch 4: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc25bc7a37c493a99a6907670f6fe08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4/6 \t train : loss 0.35285 - spearmanr 0.43613\n",
      "epoch 4: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6af02f888254a28b1dc783cec247be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4/6 \t valid : loss 0.37054 - spearmanr 0.39433\n",
      "best model: epoch 4 - 0.39433\n",
      "epoch 5: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a922a8d9ce9f407480c5eb6d1250c4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fe75fe5db8b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mbatch_step_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     )\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfold_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0moofs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/KaggleProjects/GoogleQuest/learning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             self.info(self._get_metric_string(\n\u001b[1;32m     99\u001b[0m                 epoch, train_loss, train_metrics))\n",
      "\u001b[0;32m~/Projects/KaggleProjects/GoogleQuest/learning.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/KaggleProjects/GoogleQuest/learning.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch_inputs, batch_targets, batch_idx)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_accum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_accum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, random_state=42)\n",
    "oofs = np.zeros((len(train), N_TARGETS))\n",
    "preds = np.zeros((len(test), N_TARGETS))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(folds.split(train)):\n",
    "    print(f'Fold {fold_id + 1} started at {time.ctime()}')\n",
    "    train_loader = DataLoader(\n",
    "        TextDataset3(cat_features_train, ids_train['question'], ids_train['answer'], train_index, y),\n",
    "        batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TextDataset3(cat_features_train, ids_train['question'], ids_train['answer'], valid_index, y),\n",
    "        batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "        \n",
    "    model = CustomBert6(256, cat_features_train.shape[1])\n",
    "    \n",
    "    if fold_id == 0:\n",
    "        print(model)\n",
    "        model = model.to(device)\n",
    "        optimizer = get_optimizer(model, lr, weight_decay)\n",
    "        lr_finder = LRFinder(n_iter=min(grad_accum*100, len(train_loader)), start_lr=1e-5, \n",
    "                             end_lr=1, device=device, grad_accum=grad_accum, divergence_factor=3)\n",
    "        lr_finder.find_lr(model, optimizer, train_loader, loss_fn)\n",
    "        plt.show()\n",
    "    \n",
    "    optimizer = get_optimizer(model, lr, weight_decay)\n",
    "    #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1)\n",
    "    scheduler = OneCycleLR(optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "\n",
    "    learner = Learner(\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        n_epochs, \n",
    "        f'{model_name}_fold_{fold_id + 1}', \n",
    "        checkpoint_dir, \n",
    "        scheduler=scheduler, \n",
    "        metric_fns={'spearmanr': (spearmanr_torch, 'epoch_end')}, \n",
    "        monitor_metric='spearmanr',\n",
    "        minimize_score=False, \n",
    "        logger=None,\n",
    "        grad_accum=grad_accum,\n",
    "        early_stopping=early_stopping, \n",
    "        batch_step_scheduler=True\n",
    "    )\n",
    "    if (fold_id + 1) > 0: learner.train()\n",
    "    \n",
    "    oofs[valid_index] = infer(learner.model, valid_loader, learner.best_checkpoint_file, device)\n",
    "    \n",
    "    test_preds = infer(learner.model, test_loader, learner.best_checkpoint_file, device)\n",
    "    preds += test_preds / folds.n_splits\n",
    "    \n",
    "    del learner, model, train_loader, valid_loader\n",
    "    gc.collect()\n",
    "    \n",
    "print(f'OOF score: {spearmanr_np(oofs, y)}')\n",
    "#0.4003#0.4119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping is necessary or we will get an error\n",
    "sample_submission.loc[:, 'question_asker_intent_understanding':] = np.clip(preds, 0.00001, 0.999999)\n",
    "sample_submission.to_csv('subs/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
