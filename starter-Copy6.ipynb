{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import nltk.data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "from radam import RAdam\n",
    "from text_data import TextDataset3, AugTextDataset, TextDataset7, collate_fn\n",
    "from bert import CustomBert3, CustomBert7\n",
    "from learning import Learner\n",
    "from lr_finder import LRFinder\n",
    "from one_cycle import OneCycleLR\n",
    "from text_cleaning import clean_data\n",
    "from sentence_embed import get_use_embedding_features, get_distill_bert_features\n",
    "from create_features import get_dist_features, get_categorical_features\n",
    "from losses_metrics import spearmanr_torch, spearmanr_np, FocalLoss\n",
    "from inference import infer\n",
    "from eda import eda\n",
    "from common import *\n",
    "from utils.helpers import init_logger, init_seed\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "path = 'data/'\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
    "test = pd.read_csv(f'{path}test.csv').fillna(' ')\n",
    "train = pd.read_csv(f'{path}train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question'] = train['question_title'] + ' [SEP] ' + train['question_body']\n",
    "test['question'] = test['question_title'] + ' [SEP] ' + test['question_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9361b0d540949bcae08c5e5863a9463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c47424195046bc89a5e8bf23e95d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdfe8a0effc46de92b76cb9dde46a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb6b66042a94e85931e7c62b7845b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 29.8 s, sys: 217 ms, total: 30.1 s\n",
      "Wall time: 30.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "ids_train = {}\n",
    "ids_test = {}\n",
    "max_seq_len = 512\n",
    "max_n_seqs = 5\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text in ['question', 'answer']:\n",
    "        ids = []\n",
    "        text_ = text if text == 'answer' else 'question_body'\n",
    "        for i, x in enumerate(tqdm(df[text_].values)):\n",
    "            \n",
    "            if text == 'question':\n",
    "                title = ' '.join(bert_tokenizer.tokenize(df['question_title'].values[i])) + ' [SEP] '\n",
    "            else:\n",
    "                title = ''\n",
    "            sentences = sentence_tokenizer.tokenize(x)\n",
    "            sentences = [' '.join(bert_tokenizer.tokenize(s)) for s in sentences]\n",
    "            if len(sentences) == 0: senetences.append('')\n",
    "            \n",
    "            curr_seq_len = 0\n",
    "            seq, seqs = title, []\n",
    "            for i, s in enumerate(sentences):\n",
    "                new_seq = seq + ' ' + s\n",
    "                curr_seq_len = len(new_seq.split())\n",
    "                \n",
    "                if ((i != (len(sentences) - 1)) \n",
    "                    and (curr_seq_len < (max_seq_len - 2))): # account for [CLS] and [SEP] tokens\n",
    "                    seq = new_seq\n",
    "                else:\n",
    "                    seq_ids = bert_tokenizer.convert_tokens_to_ids(seq.split())\n",
    "                    encoded_inputs = bert_tokenizer.prepare_for_model(\n",
    "                        seq_ids, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)\n",
    "                    seqs.append(encoded_inputs['input_ids'])\n",
    "                    if text == 'question': seq = title + ' ' + s\n",
    "                    else: seq = s\n",
    "            \n",
    "                        \n",
    "            ids.append(seqs[:max_n_seqs])\n",
    "        if mode == 'train': ids_train[text] = np.array(ids)\n",
    "        else: ids_test[text] = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_host, test_host, host_dict, host_dict_reverse = get_categorical_features(train, test, 'host')\n",
    "train_category, test_category, category_dict, category_dict_reverse = \\\n",
    "    get_categorical_features(train, test, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_features_train = np.hstack([train_host.reshape(-1, 1), train_category.reshape(-1, 1)])\n",
    "cat_features_test = np.hstack([test_host.reshape(-1, 1), test_category.reshape(-1, 1)])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(cat_features_train)\n",
    "cat_features_train = ohe.transform(cat_features_train).toarray()\n",
    "cat_features_test = ohe.transform(cat_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[TARGETS].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10\n",
    "bs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "class LongestFirstSequentialSampler(SequentialSampler):\n",
    "    def __iter__(self):\n",
    "        l = list(range(len(self.data_source)))\n",
    "        l.remove(self.data_source.longest_idx)\n",
    "        return iter([self.data_source.longest_idx] + l)\n",
    "\n",
    "class LongestFirstRandomSampler(RandomSampler):\n",
    "    def __iter__(self):\n",
    "        n = len(self.data_source)\n",
    "        if self.replacement:\n",
    "            l = torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist()\n",
    "        else:\n",
    "            l = torch.randperm(n).tolist()\n",
    "        l.remove(self.data_source.longest_idx)\n",
    "        return iter([self.data_source.longest_idx] + l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_test = 2\n",
    "test_ds = TextDataset7(cat_features_test, ids_test['question'], ids_test['answer'], test.index)\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=bs_test, shuffle=False, num_workers=num_workers, drop_last=False, collate_fn=collate_fn, \n",
    "    sampler=LongestFirstSequentialSampler(test_ds)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRankingLoss(nn.MSELoss):\n",
    "    def forward(self, input, target):\n",
    "        input = torch.sigmoid(input)\n",
    "        n = input.size(0)\n",
    "        n_pairs = n // 2\n",
    "        n_tot_pairs = n_pairs + (n % 2)\n",
    "        loss = 0\n",
    "        for i in range(n_pairs):\n",
    "            dp = input[2*i] - input[(2*i)+1]\n",
    "            dy = target[2*i] - target[(2*i)+1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "            \n",
    "        if n_tot_pairs > n_pairs:\n",
    "            dp = input[-2] - input[-1]\n",
    "            dy = target[-2] - target[-1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "        return loss\n",
    "    \n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=N_TARGETS*[1.0]):\n",
    "        super().__init__()\n",
    "        pos_weight = torch.Tensor(pos_weight).cuda()\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='mean', pos_weight=pos_weight)\n",
    "        self.mrl = MyRankingLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = (1. * self.bce(input, target) + 1. * self.mrl(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = 'cuda'\n",
    "n_epochs = 4\n",
    "grad_accum = 4\n",
    "weight_decay = 0.01\n",
    "model_name = 'double_distil_bert'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import text_data\n",
    "reload(text_data)\n",
    "from text_data import TextDataset7, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_param_groups(model, lr, weight_decay):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': weight_decay, 'lr': lr},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0, 'lr': lr}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr, weight_decay):\n",
    "    return transformers.AdamW(\n",
    "        get_optimizer_param_groups(model.head, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.q_add, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.a_add, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.q_bert, lr / 100, weight_decay)\n",
    "        + get_optimizer_param_groups(model.a_bert, lr / 100, weight_decay)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Mon Jan  6 23:30:20 2020\n",
      "CustomBert7(\n",
      "  (q_add): AddSeq(\n",
      "    (lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (a_add): AddSeq(\n",
      "    (lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (q_bert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (a_bert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): HeadNet2(\n",
      "    (lin): Sequential(\n",
      "      (0): Linear(in_features=1604, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_q): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_a): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (head_q): Linear(in_features=512, out_features=21, bias=True)\n",
      "    (head_a): Linear(in_features=512, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdaa43b91284c05bb05d93a47ecdb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8d8691ebb047d280cbb23cdc9a4bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2432), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 8.\nOriginal Traceback (most recent call last):\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/Projects/KaggleProjects/GoogleQuest/text_data.py\", line 174, in __getitem__\n    else: q_ids = q_ids[0]\nIndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-efbea6874274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mbatch_step_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     )\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfold_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0moofs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/KaggleProjects/GoogleQuest/learning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             self.info(self._get_metric_string(\n\u001b[1;32m     99\u001b[0m                 epoch, train_loss, train_metrics))\n",
      "\u001b[0;32m~/Projects/KaggleProjects/GoogleQuest/learning.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mcurr_loss_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_metric_avgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_fns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 8.\nOriginal Traceback (most recent call last):\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/Projects/KaggleProjects/GoogleQuest/text_data.py\", line 174, in __getitem__\n    else: q_ids = q_ids[0]\nIndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "init_seed()\n",
    "folds = GroupKFold(n_splits=5).split(\n",
    "    X=train['question_body'], groups=train['question_body'])#KFold(n_splits=5, random_state=42).split(train)\n",
    "oofs = np.zeros((len(train), N_TARGETS))\n",
    "preds = np.zeros((len(test), N_TARGETS))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(folds):\n",
    "    print(f'Fold {fold_id + 1} started at {time.ctime()}')\n",
    "    train_ds = TextDataset7(\n",
    "        cat_features_train, ids_train['question'], ids_train['answer'], train_index, targets=y)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=bs, shuffle=False, num_workers=num_workers, drop_last=False, collate_fn=collate_fn, \n",
    "        sampler=LongestFirstRandomSampler(train_ds)\n",
    "    )\n",
    "    valid_ds = TextDataset7(\n",
    "        cat_features_train, ids_train['question'], ids_train['answer'], valid_index, targets=y)\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds, batch_size=bs, shuffle=False, num_workers=num_workers, drop_last=False, collate_fn=collate_fn, \n",
    "        sampler=LongestFirstSequentialSampler(valid_ds)\n",
    "    )\n",
    "    model = CustomBert7(256, cat_features_train.shape[1])\n",
    "    \n",
    "    if fold_id == 0:\n",
    "        print(model)\n",
    "        model = model.to(device)\n",
    "        optimizer = get_optimizer(model, lr, weight_decay)\n",
    "        lr_finder = LRFinder(n_iter=min(grad_accum*100, len(train_loader)), start_lr=1e-5, \n",
    "                             end_lr=1, device=device, grad_accum=grad_accum, divergence_factor=5)\n",
    "        lr_finder.find_lr(model, optimizer, train_loader, loss_fn)\n",
    "        plt.show()\n",
    "        del lr_finder\n",
    "    \n",
    "    optimizer = get_optimizer(model, lr, weight_decay)\n",
    "    scheduler = OneCycleLR(optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "\n",
    "    learner = Learner(\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        n_epochs, \n",
    "        f'{model_name}_fold_{fold_id + 1}', \n",
    "        checkpoint_dir, \n",
    "        scheduler=scheduler, \n",
    "        metric_fns={'spearmanr': (spearmanr_torch, 'epoch_end')}, \n",
    "        monitor_metric='spearmanr',\n",
    "        minimize_score=False, \n",
    "        logger=None,\n",
    "        grad_accum=grad_accum,\n",
    "        early_stopping=early_stopping, \n",
    "        batch_step_scheduler=True\n",
    "    )\n",
    "    if (fold_id + 1) > 0: learner.train()\n",
    "    \n",
    "    oofs[valid_index] = infer(learner.model, valid_loader, learner.best_checkpoint_file, device)\n",
    "    \n",
    "    test_preds = infer(learner.model, test_loader, learner.best_checkpoint_file, device)\n",
    "    preds += test_preds / 5\n",
    "    \n",
    "    del learner, model, train_loader, valid_loader\n",
    "    gc.collect()\n",
    "    \n",
    "print(f'OOF score: {spearmanr_np(oofs, y)}')\n",
    "#0.4134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/Projects/KaggleProjects/GoogleQuest/text_data.py\", line 174, in __getitem__\n    else: q_ids = q_ids[0]\nIndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d184f2769f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/robin/Projects/KaggleProjects/GoogleQuest/text_data.py\", line 174, in __getitem__\n    else: q_ids = q_ids[0]\nIndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "for b in train_loader:\n",
    "    b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4863"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.question_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2b707682ac496e9e3f76ccac502833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4863), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bd228609876c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/KaggleProjects/GoogleQuest/text_data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mn_q_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_q_seq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mq_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mq_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0ma_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_ds))): \n",
    "    train_ds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[24,24],[43,21]]).max(dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[(i, train_loader.dataset[i][0][3]) for i in range(5, 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [train_loader.dataset[i] for i in range(6,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = lambda x: torch.tensor(x)\n",
    "x_feats, q_ids, a_ids, n_q_seq, n_a_seq, targets = [], [], [], [], [], []\n",
    "for b in batch:\n",
    "    (x, q, a, n_q, n_a), t = b\n",
    "    x_feats.append(x)\n",
    "    q_ids.append(q)\n",
    "    a_ids.append(a)\n",
    "    n_q_seq.append(n_q)\n",
    "    n_a_seq.append(n_a)\n",
    "    targets.append(t)\n",
    "\n",
    "x_feats = T(np.vstack(x_feats))\n",
    "q_ids = T(np.vstack(q_ids))\n",
    "a_ids = T(np.vstack(a_ids))\n",
    "n_q_seq = T(np.array(n_q_seq))\n",
    "n_a_seq = T(np.array(n_a_seq))\n",
    "targets = T(np.vstack(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_feats.shape, q_ids.shape, a_ids.shape, n_q_seq, n_a_seq, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feats.type(), q_ids.type(), a_ids.type(), n_q_seq.type(), n_a_seq.type(), targets.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_round(x, num, dec=2):\n",
    "    return np.round(x / num, dec) * num\n",
    "\n",
    "def round_preds(preds, thres=0.0, low_dec=1, low_num=1, high_dec=2, high_num=3):\n",
    "    low_idx = preds < thres\n",
    "    new_preds = np.zeros_like(preds)\n",
    "    new_preds[low_idx] = my_round(preds[low_idx], low_num, low_dec)\n",
    "    new_preds[~low_idx] = my_round(preds[~low_idx], high_num, high_dec)\n",
    "    return new_preds\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "def spearmanr_np(preds, targets):\n",
    "    score = 0\n",
    "    for i in range(N_TARGETS):\n",
    "        score_i = spearmanr(preds[:, i], targets[:, i]).correlation\n",
    "        score += np.nan_to_num(score_i / N_TARGETS)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_idx = np.where(y.mean(axis=0).round(3)<=0.001)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_round(oofs, 3, 2), oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr_np(oofs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spearmanr_np(np.clip(round_preds(oofs, high_num=3), 0.00001, 0.999999), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping is necessary or we will get an error\n",
    "sample_submission.loc[:, 'question_asker_intent_understanding':] = np.clip(preds, 0.00001, 0.999999)\n",
    "sample_submission.to_csv('subs/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
