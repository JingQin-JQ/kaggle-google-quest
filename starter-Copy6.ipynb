{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import nltk.data\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "from radam import RAdam\n",
    "from text_data import TextDataset3, AugTextDataset, TextDataset7, collate_fn\n",
    "from bert import CustomBert3, CustomBert7\n",
    "from learning import Learner\n",
    "from lr_finder import LRFinder\n",
    "from one_cycle import OneCycleLR\n",
    "from text_cleaning import clean_data\n",
    "from sentence_embed import get_use_embedding_features, get_distill_bert_features\n",
    "from create_features import get_dist_features, get_categorical_features\n",
    "from losses_metrics import spearmanr_torch, spearmanr_np, FocalLoss\n",
    "from inference import infer\n",
    "from eda import eda\n",
    "from common import *\n",
    "from utils.helpers import init_logger, init_seed\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "path = 'data/'\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
    "test = pd.read_csv(f'{path}test.csv').fillna(' ')\n",
    "train = pd.read_csv(f'{path}train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question'] = train['question_title'] + ' [SEP] ' + train['question_body']\n",
    "test['question'] = test['question_title'] + ' [SEP] ' + test['question_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df96170f4bfb4634b9f0eca9b67569c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941197f1d7a14b6f99df9f1fb67491b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac46f3b929cd41499b011771a39197b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e8eb4f415c4ce790c11288937cfa50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 30.3 s, sys: 278 ms, total: 30.6 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "ids_train = {}\n",
    "ids_test = {}\n",
    "max_seq_len = 512\n",
    "max_n_seqs = 5\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text in ['question', 'answer']:\n",
    "        ids = []\n",
    "        text_ = text if text == 'answer' else 'question_body'\n",
    "        for i, x in enumerate(tqdm(df[text_].values)):\n",
    "            \n",
    "            if text == 'question':\n",
    "                title = ' '.join(bert_tokenizer.tokenize(df['question_title'].values[i])) + ' [SEP] '\n",
    "            else:\n",
    "                title = ''\n",
    "            sentences = sentence_tokenizer.tokenize(x)\n",
    "            sentences = [' '.join(bert_tokenizer.tokenize(s)) for s in sentences]\n",
    "            if len(sentences) == 0: sentences.append('')\n",
    "            \n",
    "            curr_seq_len = 0\n",
    "            seq, seqs = title, []\n",
    "            for i, s in enumerate(sentences):\n",
    "                new_seq = seq + ' ' + s\n",
    "                curr_seq_len = len(new_seq.split())\n",
    "                \n",
    "                if ((i != len(sentences)-1) and (curr_seq_len < max_seq_len-2)): #account for [CLS] and [SEP]\n",
    "                    seq = new_seq\n",
    "                else:\n",
    "                    if i == (len(sentences) - 1): \n",
    "                        seq = new_seq\n",
    "                    seq_ids = bert_tokenizer.convert_tokens_to_ids(seq.split())\n",
    "                    encoded_inputs = bert_tokenizer.prepare_for_model(\n",
    "                        seq_ids, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)\n",
    "                    seqs.append(encoded_inputs['input_ids'])\n",
    "                    seq = title + ' ' + s\n",
    "                        \n",
    "            ids.append(seqs[:max_n_seqs])\n",
    "        if mode == 'train': ids_train[text] = np.array(ids)\n",
    "        else: ids_test[text] = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_host, test_host, host_dict, host_dict_reverse = get_categorical_features(train, test, 'host')\n",
    "train_category, test_category, category_dict, category_dict_reverse = \\\n",
    "    get_categorical_features(train, test, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_features_train = np.hstack([train_host.reshape(-1, 1), train_category.reshape(-1, 1)])\n",
    "cat_features_test = np.hstack([test_host.reshape(-1, 1), test_category.reshape(-1, 1)])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(cat_features_train)\n",
    "cat_features_train = ohe.transform(cat_features_train).toarray()\n",
    "cat_features_test = ohe.transform(cat_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[TARGETS].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10\n",
    "bs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "class LongestFirstSequentialSampler(SequentialSampler):\n",
    "    def __iter__(self):\n",
    "        l = list(range(len(self.data_source)))\n",
    "        l.remove(self.data_source.longest_idx)\n",
    "        return iter([self.data_source.longest_idx] + l)\n",
    "\n",
    "class LongestFirstRandomSampler(RandomSampler):\n",
    "    def __iter__(self):\n",
    "        n = len(self.data_source)\n",
    "        if self.replacement:\n",
    "            l = torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist()\n",
    "        else:\n",
    "            l = torch.randperm(n).tolist()\n",
    "        l.remove(self.data_source.longest_idx)\n",
    "        return iter([self.data_source.longest_idx] + l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_test = 2\n",
    "test_ds = TextDataset7(cat_features_test, ids_test['question'], ids_test['answer'], test.index)\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=bs_test, shuffle=False, num_workers=num_workers, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRankingLoss(nn.MSELoss):\n",
    "    def forward(self, input, target):\n",
    "        input = torch.sigmoid(input)\n",
    "        n = input.size(0)\n",
    "        n_pairs = n // 2\n",
    "        n_tot_pairs = n_pairs + (n % 2)\n",
    "        loss = 0\n",
    "        for i in range(n_pairs):\n",
    "            dp = input[2*i] - input[(2*i)+1]\n",
    "            dy = target[2*i] - target[(2*i)+1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "            \n",
    "        if n_tot_pairs > n_pairs:\n",
    "            dp = input[-2] - input[-1]\n",
    "            dy = target[-2] - target[-1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "        return loss\n",
    "    \n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=N_TARGETS*[1.0]):\n",
    "        super().__init__()\n",
    "        pos_weight = torch.Tensor(pos_weight).cuda()\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='mean', pos_weight=pos_weight)\n",
    "        self.mrl = MyRankingLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = (1. * self.bce(input, target) + 1. * self.mrl(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = 'cuda'\n",
    "n_epochs = 4\n",
    "grad_accum = 4\n",
    "weight_decay = 0.01\n",
    "model_name = 'double_distil_bert'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import text_data\n",
    "reload(text_data)\n",
    "from text_data import TextDataset7, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_param_groups(model, lr, weight_decay):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': weight_decay, 'lr': lr},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0, 'lr': lr}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr, weight_decay):\n",
    "    return transformers.AdamW(\n",
    "        get_optimizer_param_groups(model.head, lr, weight_decay)\n",
    "#         + get_optimizer_param_groups(model.q_add, lr, weight_decay)\n",
    "#         + get_optimizer_param_groups(model.a_add, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.q_bert, lr / 100, weight_decay)\n",
    "        + get_optimizer_param_groups(model.a_bert, lr / 100, weight_decay)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Tue Jan  7 23:06:35 2020\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e458e651c9f49b99d5a3764ddbf4345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57383da7db24e2abc8f34d38d6f9b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 started at Tue Jan  7 23:07:18 2020\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_2_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10e6b3609ce4db5b9880e22f88c7bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_2_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb26d1728b554c279db12304c22115fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 started at Tue Jan  7 23:07:58 2020\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_3_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1f7f968c084a3ebec0b5a5fa49ce7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_3_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73427d9cf54c4757a5ea5223e5aa3b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 started at Tue Jan  7 23:08:35 2020\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_4_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb68914d8ec46f381afcacdd0513868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_4_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ffe0a71317464dbaf385a56d5a5a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5 started at Tue Jan  7 23:09:15 2020\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_5_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d51e02c5284a8eb755dbecd9134c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=608), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_5_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e205c1a39484e6a80c8f7c07f412f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOF score: 0.4125770538649285\n"
     ]
    }
   ],
   "source": [
    "init_seed()\n",
    "folds = GroupKFold(n_splits=5).split(\n",
    "    X=train['question_body'], groups=train['question_body'])#KFold(n_splits=5, random_state=42).split(train)\n",
    "oofs = np.zeros((len(train), N_TARGETS))\n",
    "preds = np.zeros((len(test), N_TARGETS))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(folds):\n",
    "    print(f'Fold {fold_id + 1} started at {time.ctime()}')\n",
    "    train_ds = TextDataset7(\n",
    "        cat_features_train, ids_train['question'], ids_train['answer'], train_index, targets=y)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=bs, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, \n",
    "        sampler=LongestFirstRandomSampler(train_ds)\n",
    "    )\n",
    "    valid_ds = TextDataset7(\n",
    "        cat_features_train, ids_train['question'], ids_train['answer'], valid_index, targets=y)\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds, batch_size=bs, shuffle=False, num_workers=num_workers, collate_fn=collate_fn)\n",
    "    model = CustomBert7(256, cat_features_train.shape[1])\n",
    "    \n",
    "    if fold_id == -1:\n",
    "        print(model)\n",
    "        model = model.to(device)\n",
    "        optimizer = get_optimizer(model, lr, weight_decay)\n",
    "        lr_finder = LRFinder(n_iter=min(grad_accum*100, len(train_loader)), start_lr=1e-5, \n",
    "                             end_lr=1, device=device, grad_accum=grad_accum, divergence_factor=5)\n",
    "        lr_finder.find_lr(model, optimizer, train_loader, loss_fn)\n",
    "        plt.show()\n",
    "        del lr_finder\n",
    "    \n",
    "    optimizer = get_optimizer(model, lr, weight_decay)\n",
    "    scheduler = OneCycleLR(optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "\n",
    "    learner = Learner(\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        n_epochs, \n",
    "        f'{model_name}_fold_{fold_id + 1}', \n",
    "        checkpoint_dir, \n",
    "        scheduler=scheduler, \n",
    "        metric_fns={'spearmanr': (spearmanr_torch, 'epoch_end')}, \n",
    "        monitor_metric='spearmanr',\n",
    "        minimize_score=False, \n",
    "        logger=None,\n",
    "        grad_accum=grad_accum,\n",
    "        early_stopping=early_stopping, \n",
    "        batch_step_scheduler=True\n",
    "    )\n",
    "    if (fold_id + 1) > 5: learner.train()\n",
    "    \n",
    "    oofs[valid_index] = infer(learner.model, valid_loader, learner.best_checkpoint_file, device)\n",
    "    \n",
    "    test_preds = infer(learner.model, test_loader, learner.best_checkpoint_file, device)\n",
    "    preds += test_preds / 5\n",
    "    \n",
    "    del learner, model, train_loader, valid_loader\n",
    "    gc.collect()\n",
    "    \n",
    "print(f'OOF score: {spearmanr_np(oofs, y)}')\n",
    "#0.4134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_round(x, num, dec=2):\n",
    "    return np.round(x / num, dec) * num\n",
    "\n",
    "def round_preds(preds, thres=0.0, low_dec=1, low_num=1, high_dec=2, high_num=3):\n",
    "    low_idx = preds < thres\n",
    "    new_preds = np.zeros_like(preds)\n",
    "    new_preds[low_idx] = my_round(preds[low_idx], low_num, low_dec)\n",
    "    new_preds[~low_idx] = my_round(preds[~low_idx], high_num, high_dec)\n",
    "    return new_preds\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "def spearmanr_np(preds, targets):\n",
    "    score = 0\n",
    "    for i in range(N_TARGETS):\n",
    "        score_i = spearmanr(preds[:, i], targets[:, i]).correlation\n",
    "        score += np.nan_to_num(score_i / N_TARGETS)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39705861271883985"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr_np(oofs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4109852174556347"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr_np(np.clip(round_preds(oofs, high_num=2), 0.00001, 0.999999), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping is necessary or we will get an error\n",
    "sample_submission.loc[:, 'question_asker_intent_understanding':] = np.clip(preds, 0.00001, 0.999999)\n",
    "sample_submission.to_csv('subs/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
