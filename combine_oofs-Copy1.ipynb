{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'data/train.csv')\n",
    "TARGETS = train.columns[11:]\n",
    "\n",
    "for col in TARGETS:\n",
    "    train[col] = train[col].rank(method=\"average\")\n",
    "train[TARGETS] = MinMaxScaler().fit_transform(train[TARGETS])\n",
    "y = train[TARGETS].values\n",
    "ix = np.where(train.groupby(\"question_body\")[\"host\"].transform(\"count\") == 1)[0]\n",
    "\n",
    "y_use = pd.read_csv('oofs/use_oof.csv').values\n",
    "y_albert = pd.read_csv('oofs/siamese_albert_1_comb_oofs.csv', index_col=0).values\n",
    "y_bert = pd.read_csv('oofs/siamese_bert_6_oofs.csv', index_col=0).values\n",
    "y_roberta = pd.read_csv('oofs/siamese_roberta_1_comb_oofs.csv', index_col=0).values\n",
    "y_xlnet = pd.read_csv('oofs/siamese_xlnet_1_comb_oofs.csv', index_col=0).values\n",
    "# y_xlnet = pd.read_csv('oofs/siamese_xlnet_2_comb_oofs.csv', index_col=0).values\n",
    "\n",
    "preds = [y_use, y_roberta, y_bert, y_xlnet, y_albert]\n",
    "n_models = len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y, y_pred, verbose=False, exclude=[]):\n",
    "    score = 0\n",
    "    for i in range(y.shape[1]):\n",
    "        if i not in exclude:\n",
    "            col_score = spearmanr(y[:, i], y_pred[:, i])[0]\n",
    "            if verbose:\n",
    "                print(TARGETS[i], np.round(col_score, 3))\n",
    "            score += col_score/(y.shape[1]-len(exclude))\n",
    "    return np.round(score, 4)\n",
    "\n",
    "\n",
    "ds = [4, 8, 16, 32, 64, None]\n",
    "\n",
    "\n",
    "def scale(x, d):\n",
    "    if d:\n",
    "        return (x//(1/d))/d\n",
    "    return x\n",
    "\n",
    "ds2 = list(itertools.product(ds, ds))\n",
    "\n",
    "\n",
    "def transform(preds, params, c):\n",
    "    d_global, d_local = params\n",
    "    X = np.vstack(preds).T\n",
    "    ws, _, _, _ = np.linalg.lstsq(X, y[:,c].reshape(-1,1))\n",
    "    ws = np.round(ws, 2)\n",
    "    y_temp = (X @ ws).flatten()\n",
    "    y_temp /= sum(ws)\n",
    "    y_temp = scale(y_temp, d_global)\n",
    "    return y_temp\n",
    "\n",
    "\n",
    "def f(c):\n",
    "    max_score = spearmanr(y[:, c], y_roberta[:, c])[0]\n",
    "    best_index = -1\n",
    "    for i, params in enumerate(dws5):\n",
    "        y_temp = transform(preds, params, c)\n",
    "        score = spearmanr(y[:, c], y_temp)[0]\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_index = i\n",
    "            \n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(15)\n",
    "out = pool.map(f, range(N_TARGETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 question_asker_intent_understanding (None, 16)\n",
      "1 question_body_critical (None, 64)\n",
      "2 question_conversational (4, None)\n",
      "3 question_expect_short_answer (32, 64)\n",
      "4 question_fact_seeking (16, 32)\n",
      "5 question_has_commonly_accepted_answer (None, 2)\n",
      "6 question_interestingness_others (64, None)\n",
      "7 question_interestingness_self (16, None)\n",
      "8 question_multi_intent (8, 32)\n",
      "9 question_not_really_a_question (32, None)\n",
      "10 question_opinion_seeking (32, 16)\n",
      "11 question_type_choice (16, 4)\n",
      "12 question_type_compare (4, None)\n",
      "13 question_type_consequence (16, 4)\n",
      "14 question_type_definition (8, 8)\n",
      "15 question_type_entity (8, 8)\n",
      "16 question_type_instructions (16, 4)\n",
      "17 question_type_procedure (32, 16)\n",
      "18 question_type_reason_explanation (32, 64)\n",
      "19 question_type_spelling (32, 16)\n",
      "20 question_well_written (None, 64)\n",
      "21 answer_helpful (None, 8)\n",
      "22 answer_level_of_information (64, None)\n",
      "23 answer_plausible (16, None)\n",
      "24 answer_relevance (32, None)\n",
      "25 answer_satisfaction (16, 64)\n",
      "26 answer_type_instructions (32, 64)\n",
      "27 answer_type_procedure (None, None)\n",
      "28 answer_type_reason_explanation (64, 32)\n",
      "29 answer_well_written (None, None)\n"
     ]
    }
   ],
   "source": [
    "y_combined = np.zeros(y.shape)\n",
    "\n",
    "for c in range(30):\n",
    "    print(c, TARGETS[c], ds2[out[c]])\n",
    "    y_combined[:, c] = transform(y_use, y_albert, y_roberta, y_bert, y_xlnet, ds2[out[c]], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding 0.401\n",
      "question_body_critical 0.67\n",
      "question_conversational 0.504\n",
      "question_expect_short_answer 0.323\n",
      "question_fact_seeking 0.378\n",
      "question_has_commonly_accepted_answer 0.479\n",
      "question_interestingness_others 0.368\n",
      "question_interestingness_self 0.522\n",
      "question_multi_intent 0.608\n",
      "question_not_really_a_question 0.152\n",
      "question_opinion_seeking 0.497\n",
      "question_type_choice 0.773\n",
      "question_type_compare 0.565\n",
      "question_type_consequence 0.264\n",
      "question_type_definition 0.653\n",
      "question_type_entity 0.612\n",
      "question_type_instructions 0.792\n",
      "question_type_procedure 0.384\n",
      "question_type_reason_explanation 0.685\n",
      "question_type_spelling 0.497\n",
      "question_well_written 0.537\n",
      "answer_helpful 0.275\n",
      "answer_level_of_information 0.472\n",
      "answer_plausible 0.167\n",
      "answer_relevance 0.192\n",
      "answer_satisfaction 0.378\n",
      "answer_type_instructions 0.773\n",
      "answer_type_procedure 0.327\n",
      "answer_type_reason_explanation 0.7\n",
      "answer_well_written 0.245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4731"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(y, y_combined, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_asker_intent_understanding 0.401\n",
      "question_body_critical 0.67\n",
      "question_conversational 0.504\n",
      "question_expect_short_answer 0.323\n",
      "question_fact_seeking 0.378\n",
      "question_has_commonly_accepted_answer 0.479\n",
      "question_interestingness_others 0.368\n",
      "question_interestingness_self 0.522\n",
      "question_multi_intent 0.608\n",
      "question_opinion_seeking 0.497\n",
      "question_type_choice 0.773\n",
      "question_type_compare 0.565\n",
      "question_type_consequence 0.264\n",
      "question_type_definition 0.653\n",
      "question_type_entity 0.612\n",
      "question_type_instructions 0.792\n",
      "question_type_procedure 0.384\n",
      "question_type_reason_explanation 0.685\n",
      "question_well_written 0.537\n",
      "answer_helpful 0.275\n",
      "answer_level_of_information 0.472\n",
      "answer_plausible 0.167\n",
      "answer_relevance 0.192\n",
      "answer_satisfaction 0.378\n",
      "answer_type_instructions 0.773\n",
      "answer_type_procedure 0.327\n",
      "answer_type_reason_explanation 0.7\n",
      "answer_well_written 0.245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4837"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(y, y_combined, True, exclude=[9,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 16),\n",
       " (None, 64),\n",
       " (4, None),\n",
       " (32, 64),\n",
       " (16, 32),\n",
       " (None, 2),\n",
       " (64, None),\n",
       " (16, None),\n",
       " (8, 32),\n",
       " (32, None),\n",
       " (32, 16),\n",
       " (16, 4),\n",
       " (4, None),\n",
       " (16, 4),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (16, 4),\n",
       " (32, 16),\n",
       " (32, 64),\n",
       " (32, 16),\n",
       " (None, 64),\n",
       " (None, 8),\n",
       " (64, None),\n",
       " (16, None),\n",
       " (32, None),\n",
       " (16, 64),\n",
       " (32, 64),\n",
       " (None, None),\n",
       " (64, 32),\n",
       " (None, None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ds2[out[c]] for c in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
