{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import DistilBertTokenizer, BertTokenizer\n",
    "import transformers\n",
    "\n",
    "from radam import RAdam\n",
    "from text_data import TextDataset5\n",
    "from bert import CustomBert3\n",
    "from multilabel_cross_fold import MultilabelStratifiedKFold\n",
    "from learning import Learner\n",
    "from lr_finder import LRFinder\n",
    "from one_cycle import OneCycleLR\n",
    "from text_cleaning import clean_data\n",
    "from create_features import get_categorical_features\n",
    "from losses_metrics import spearmanr_torch, spearmanr_np\n",
    "from inference import infer\n",
    "from eda import eda\n",
    "from common import *\n",
    "from utils.helpers import init_logger, init_seed\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "path = 'data/'\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
    "test = pd.read_csv(f'{path}test.csv').fillna(' ')\n",
    "train = pd.read_csv(f'{path}train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64353b2fc30141a4b6d4693ecbb34863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9b71fc29944c49903a5d10e3f1d438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a750b479093a4046906f7db7a056fd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d242b543170b477aacfc1f309190d1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 32.6 s, sys: 296 ms, total: 32.9 s\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "seg_ids_train, ids_train = {}, {}\n",
    "seg_ids_test, ids_test = {}, {}\n",
    "max_seq_len = 512\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text, cols in [('question', ['question_title', 'question_body']), \n",
    "                       ('answer', ['question_title', 'answer'])]:\n",
    "        ids, seg_ids = [], []\n",
    "        for x1, x2 in tqdm(df[cols].values):\n",
    "            encoded_inputs = tokenizer.encode_plus(\n",
    "                x1, x2, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True, \n",
    "                return_token_type_ids=True\n",
    "            )\n",
    "            ids.append(encoded_inputs['input_ids'])\n",
    "            seg_ids.append(encoded_inputs['token_type_ids'])\n",
    "        if mode == 'train': \n",
    "            ids_train[text] = np.array(ids)\n",
    "            seg_ids_train[text] = np.array(seg_ids)\n",
    "        else: \n",
    "            ids_test[text] = np.array(ids)\n",
    "            seg_ids_test[text] = np.array(seg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_host, test_host, host_dict, host_dict_reverse = get_categorical_features(train, test, 'host')\n",
    "train_category, test_category, category_dict, category_dict_reverse = \\\n",
    "    get_categorical_features(train, test, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_features_train = np.hstack([train_host.reshape(-1, 1), train_category.reshape(-1, 1)])\n",
    "cat_features_test = np.hstack([test_host.reshape(-1, 1), test_category.reshape(-1, 1)])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(cat_features_train)\n",
    "cat_features_train = ohe.transform(cat_features_train).toarray()\n",
    "cat_features_test = ohe.transform(cat_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in TARGETS:\n",
    "    train[col] = train[col].rank(method=\"average\")\n",
    "train[TARGETS] = MinMaxScaler().fit_transform(train[TARGETS])\n",
    "y = train[TARGETS].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10\n",
    "bs = 2\n",
    "TextDataset = TextDataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_test = 2\n",
    "test_loader = DataLoader(\n",
    "    TextDataset(cat_features_test, ids_test['question'], ids_test['answer'], \n",
    "                seg_ids_test['question'], seg_ids_test['answer'], test.index),\n",
    "    batch_size=bs_test, shuffle=False, num_workers=num_workers, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = 'cuda'\n",
    "n_epochs = 3\n",
    "grad_accum = 4\n",
    "weight_decay = 0.01\n",
    "model_name = 'siamese_bert_3'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "early_stopping = None\n",
    "n_folds = 10\n",
    "p_aug = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_param_groups(model, lr, weight_decay):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': weight_decay, 'lr': lr},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0, 'lr': lr}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr, weight_decay):\n",
    "    return transformers.AdamW(\n",
    "        get_optimizer_param_groups(model.head, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.bert, lr / 100, weight_decay)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sat Jan 11 14:56:32 2020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a915822da5474ab111de752c5d0d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eebc7b18f34e75bd9f5803b2acb986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2736), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/3 \t train : loss 0.5057 - spearmanr 0.25856\n",
      "epoch 0: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c60bea115f4f10b8e50d49fd0444a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/3 \t valid : loss 0.47082 - spearmanr 0.38723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: epoch 0 - 0.38723\n",
      "epoch 1: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edff7e5b03947c090b27160363a8e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2736), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/3 \t train : loss 0.45165 - spearmanr 0.40824\n",
      "epoch 1: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c5c79a761748e18e363d8ee3f01c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/3 \t valid : loss 0.45274 - spearmanr 0.41564\n",
      "best model: epoch 1 - 0.41564\n",
      "epoch 2: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4553930d05bd402db419696843bf545f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2736), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/3 \t train : loss 0.42639 - spearmanr 0.47641\n",
      "epoch 2: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d7b98316dc4cdd8984aef8ac37cf86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/3 \t valid : loss 0.45032 - spearmanr 0.41951\n",
      "best model: epoch 2 - 0.41951\n",
      "TRAINING END: Best score achieved on epoch 2 - 0.41951\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd8fb1d4ebf4de19c8c6735370516c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091780f5f23d470da29ee6bfee41604b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 started at Sat Jan 11 15:27:41 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_2_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8d350035d743e3a1172167229061b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_2_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc9d2793aba4188a183b3e4d0adf083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 started at Sat Jan 11 15:28:21 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_3_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9453403717864e2b9f13aded034d7c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_3_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0055112315a48c29699cde5797327a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 started at Sat Jan 11 15:29:02 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_4_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df7f3458ecb4b04870a2fb37ef4437d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_4_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a94d3b0631e4c9f8d1e553b01ea5fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5 started at Sat Jan 11 15:29:42 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_5_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f74442ac1c241fe801243d92f5a48d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_5_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc83ce063614570bf7d43b96b9551bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 6 started at Sat Jan 11 15:30:23 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_6_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b7bd6e3c8f44aaa4a636b27cd340bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_6_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec734f6d7b74f77aa0c1486309f3c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 7 started at Sat Jan 11 15:31:03 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_7_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a602f66f95dd460188cc735934253463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_7_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d60c046fb64625818713b4493e824e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 8 started at Sat Jan 11 15:31:43 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_8_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5b632ec6df4e25aeb7621df1ea944e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_8_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8822201b1545cab435c289008e55e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 9 started at Sat Jan 11 15:32:24 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_9_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bf238ac1384711b2d6f13a5526b47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_9_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6912685259ff4b5995b4881f5c530d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 10 started at Sat Jan 11 15:33:04 2020\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_10_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d20bf2386824aa0a97e37f22a86b179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/siamese_bert_3_fold_10_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4abd265269414cb60f494159c18b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOF score: 0.41031797952499016\n"
     ]
    }
   ],
   "source": [
    "init_seed()\n",
    "folds = GroupKFold(n_splits=n_folds).split(X=train['question_body'], groups=train['question_body'])\n",
    "oofs = np.zeros((len(train), N_TARGETS))\n",
    "preds = np.zeros((len(test), N_TARGETS))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(folds):\n",
    "    print(f'Fold {fold_id + 1} started at {time.ctime()}')\n",
    "    train_loader = DataLoader(\n",
    "        TextDataset(cat_features_train, ids_train['question'], ids_train['answer'],\n",
    "                    seg_ids_train['question'], seg_ids_train['answer'], train_index, targets=y), \n",
    "        batch_size=bs, shuffle=True, num_workers=num_workers, drop_last=False\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TextDataset(cat_features_train, ids_train['question'], ids_train['answer'],\n",
    "                    seg_ids_train['question'], seg_ids_train['answer'], valid_index, targets=y), \n",
    "        batch_size=bs, shuffle=False, num_workers=num_workers, drop_last=False\n",
    "    )\n",
    "    model = CustomBert3(256, cat_features_train.shape[1])\n",
    "    \n",
    "    if fold_id == 0:\n",
    "        # print(model)\n",
    "        model = model.to(device)\n",
    "        optimizer = get_optimizer(model, lr, weight_decay)\n",
    "        lr_finder = LRFinder(n_iter=min(grad_accum*100, len(train_loader)), start_lr=1e-5, \n",
    "                             end_lr=1, device=device, grad_accum=grad_accum, divergence_factor=5)\n",
    "        lr_finder.find_lr(model, optimizer, train_loader, loss_fn)\n",
    "        plt.show()\n",
    "    \n",
    "    optimizer = get_optimizer(model, lr, weight_decay)\n",
    "    scheduler = OneCycleLR(optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "\n",
    "    learner = Learner(\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        n_epochs, \n",
    "        f'{model_name}_fold_{fold_id + 1}', \n",
    "        checkpoint_dir, \n",
    "        scheduler=scheduler, \n",
    "        metric_fns={'spearmanr': (spearmanr_torch, 'epoch_end')}, \n",
    "        monitor_metric='spearmanr',\n",
    "        minimize_score=False, \n",
    "        logger=None,\n",
    "        grad_accum=grad_accum,\n",
    "        early_stopping=early_stopping, \n",
    "        batch_step_scheduler=True\n",
    "    )\n",
    "    if (fold_id + 1) > 0: learner.train()\n",
    "    \n",
    "    oofs[valid_index] = infer(learner.model, valid_loader, learner.best_checkpoint_file, device)\n",
    "    \n",
    "    test_preds = infer(learner.model, test_loader, learner.best_checkpoint_file, device)\n",
    "    preds += test_preds / n_folds\n",
    "    \n",
    "    del learner, model, train_loader, valid_loader\n",
    "    gc.collect()\n",
    "    \n",
    "print(f'OOF score: {spearmanr_np(oofs, y)}')\n",
    "#KFold 5: distilbert: 0.4160\n",
    "#GKFold 5: distilbert: ~0.4005, ~0.4130, distilbert eda: ~0.4000, ~0.4200 (unsure), bert siamese: 0.4040, 0.4188\n",
    "    # smoothing y dist -> ~0.005 CV improve\n",
    "#GKFold 10: distilbert: 0.4012, ~0.4195, bert siamese with smoothing (1): 0.4059, 0.4206, 0.4275, 0.4449\n",
    "    #bert siamese with token_type_ids (2): 0.4091. 0.4236. 0.4317, 0.4507\n",
    "    #bert siamese for 3 epochs (3): 0.4121. 0.4273. 0.4347, 0.4497\n",
    "#MLFold 5: bert siamese: 0.4118, 0.4355, 04373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['question_conversational' 'question_has_commonly_accepted_answer'\n",
      " 'question_type_compare' 'question_type_consequence'\n",
      " 'question_type_definition' 'question_type_entity']\n"
     ]
    }
   ],
   "source": [
    "def my_round(x, num, dec=2):\n",
    "    return np.round(x / num, dec) * num\n",
    "\n",
    "def round_preds(preds, thres=0.0, low_dec=1, low_num=1, high_dec=2, high_num=3):\n",
    "    low_idx = preds < thres\n",
    "    new_preds = np.zeros_like(preds)\n",
    "    new_preds[low_idx] = my_round(preds[low_idx], low_num, low_dec)\n",
    "    new_preds[~low_idx] = my_round(preds[~low_idx], high_num, high_dec)\n",
    "    return new_preds\n",
    "\n",
    "def scale(x, d):\n",
    "    if d: return (x//(1/d))/d\n",
    "    else: return x\n",
    "\n",
    "indices = [2, 5, 12, 13, 14, 15]\n",
    "ds = [10, 5, 5, 20, 5, 5]\n",
    "discrete_cols = np.array(TARGETS)[indices]\n",
    "print(discrete_cols)\n",
    "\n",
    "def ahmet_round(preds, ds=ds, indices=indices):\n",
    "    new_preds = preds.copy()\n",
    "    for idx, d in zip(indices, ds):\n",
    "        new_preds[:,idx] = scale(preds[:,idx], d)\n",
    "    return new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 0.3241959116907673\n",
      "0 5 0.3539116872696059\n",
      "0 10 0.3790786175193342\n",
      "0 15 0.3809618339410658\n",
      "0 20 0.3815562442295259\n",
      "0 33 0.3830624472464342\n",
      "0 None 0.3837959633234947\n",
      "1 3 0.621997205813582\n",
      "1 5 0.6491972009404586\n",
      "1 10 0.6615700688224305\n",
      "1 15 0.6645963188678411\n",
      "1 20 0.6648088012312693\n",
      "1 33 0.664999038033451\n",
      "1 None 0.6657702627555317\n",
      "2 3 0.4445620586308422\n",
      "2 5 0.4867475948081961\n",
      "3 3 0.25394253330755134\n",
      "3 5 0.2884488018652375\n",
      "3 10 0.29496708151717405\n",
      "3 15 0.30087325436851753\n",
      "3 20 0.3017497598894678\n",
      "3 None 0.302804657326473\n",
      "4 3 0.3228613125456082\n",
      "4 5 0.3529720786167755\n",
      "4 10 0.3584299928559169\n",
      "4 20 0.3587882412571249\n",
      "4 33 0.359607368938582\n",
      "5 3 0.46760997660802717\n",
      "6 3 0.22062342176522914\n",
      "6 5 0.30259676865913954\n",
      "6 10 0.34530869008181186\n",
      "6 15 0.34915839098601853\n",
      "6 20 0.3507058549415688\n",
      "6 None 0.3519024942948026\n",
      "7 3 0.46378864448925705\n",
      "7 5 0.49126020044534824\n",
      "7 10 0.5001016996729669\n",
      "7 15 0.5008199270434653\n",
      "7 33 0.5019012976258539\n",
      "7 None 0.5020111217249873\n",
      "8 3 0.5551977480536431\n",
      "8 5 0.5722001570626835\n",
      "8 10 0.5755631004408873\n",
      "8 15 0.575734000172938\n",
      "8 20 0.5762595542802922\n",
      "8 33 0.5764688582770838\n",
      "9 10 0.014711599224278029\n",
      "9 15 0.09802057964858192\n",
      "9 20 0.1275624786893253\n",
      "10 3 0.43839313506771804\n",
      "10 5 0.45034475931641177\n",
      "10 10 0.46254820992352913\n",
      "10 15 0.46510379552789155\n",
      "10 20 0.46702670532428164\n",
      "10 33 0.4684310802331897\n",
      "10 None 0.46875954518369656\n",
      "11 3 0.7342758920679608\n",
      "11 5 0.7453727741061464\n",
      "11 10 0.7471013570828469\n",
      "12 3 0.5373548835092342\n",
      "13 3 0.11784521047866288\n",
      "13 5 0.19021213198278158\n",
      "13 10 0.21860742431645666\n",
      "13 15 0.2189985109994522\n",
      "13 20 0.2325234459906737\n",
      "14 3 0.5869800291252739\n",
      "14 5 0.6151128342135824\n",
      "14 10 0.6178950989105252\n",
      "15 3 0.5479372669832522\n",
      "15 5 0.5627313817833466\n",
      "16 3 0.770035692920942\n",
      "16 5 0.7739326302597296\n",
      "16 10 0.7793897789118357\n",
      "17 3 0.27488750668826223\n",
      "17 5 0.3391842157396614\n",
      "17 10 0.3521406555261752\n",
      "17 15 0.3557717253063476\n",
      "17 20 0.3581666740290085\n",
      "17 33 0.35878475129406034\n",
      "17 None 0.35892867694439395\n",
      "18 3 0.635695867376812\n",
      "18 5 0.6578844035759267\n",
      "18 10 0.6667074322504488\n",
      "18 15 0.6674283592027906\n",
      "18 20 0.6674493318202299\n",
      "18 33 0.6679956314534367\n",
      "18 None 0.6682351581517635\n",
      "19 5 0.30161062801383287\n",
      "19 10 0.3188263353947411\n",
      "19 33 0.34042364176190093\n",
      "20 3 0.47858928426200975\n",
      "20 5 0.5021694251131414\n",
      "20 10 0.517685572694397\n",
      "20 15 0.5188954748477198\n",
      "20 20 0.5212264055251261\n",
      "20 33 0.522445550155386\n",
      "21 3 0.20825832492186686\n",
      "21 5 0.21851712712762927\n",
      "21 10 0.23253874447462755\n",
      "21 15 0.2354677512006515\n",
      "21 20 0.23862887017820922\n",
      "22 3 0.3674347974292898\n",
      "22 5 0.41818827083339555\n",
      "22 10 0.4295661247903284\n",
      "22 15 0.4392389611515983\n",
      "22 20 0.4409898817611438\n",
      "22 None 0.4424296272872845\n",
      "23 3 0.08229914403496044\n",
      "23 5 0.12386878291214821\n",
      "23 10 0.1263460404401235\n",
      "23 15 0.13230280977863162\n",
      "23 33 0.13499871146202833\n",
      "23 None 0.13567373667202118\n",
      "24 3 0.12134088572895436\n",
      "24 5 0.15413341335522837\n",
      "24 10 0.16265778687139867\n",
      "24 15 0.17117247902830754\n",
      "25 3 0.2744782558902871\n",
      "25 5 0.3105729003275651\n",
      "25 10 0.3244075273345145\n",
      "25 15 0.32743341837742573\n",
      "25 20 0.3289798578053422\n",
      "25 33 0.3294054617320617\n",
      "25 None 0.33114016909728544\n",
      "26 3 0.7369093921348293\n",
      "26 5 0.7514173436071045\n",
      "26 10 0.7586653102918496\n",
      "26 15 0.7588664194678792\n",
      "27 3 0.20042837084609322\n",
      "27 5 0.27540174590074123\n",
      "27 10 0.3025473084753881\n",
      "27 15 0.304036358488835\n",
      "27 20 0.3078868582790627\n",
      "27 33 0.3086389568626305\n",
      "27 None 0.30975310949551055\n",
      "28 3 0.6426595289391042\n",
      "28 5 0.6582167529357247\n",
      "28 10 0.668181978663022\n",
      "28 15 0.6729136733835935\n",
      "28 33 0.6730050586426052\n",
      "28 None 0.6736817258295249\n",
      "29 3 0.18941608535720045\n",
      "29 5 0.2091195825369201\n",
      "29 10 0.22976825873162357\n",
      "29 15 0.23193114027962736\n",
      "29 20 0.23442538013161954\n",
      "29 33 0.23542957493830474\n",
      "29 None 0.23617661217293143\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "opt_ds = []\n",
    "opt_indices = []\n",
    "for idx in range(N_TARGETS):\n",
    "    opt_score = 0\n",
    "    opt_d = None\n",
    "    for d in [3, 5, 10, 15, 20, 33, None]:\n",
    "        score = spearmanr(scale(oofs[:,idx], d), y[:,idx])[0]\n",
    "        if score > opt_score:\n",
    "            opt_score = score\n",
    "            opt_d = d\n",
    "            print(idx, d, score)\n",
    "    if opt_d:\n",
    "        opt_ds.append(opt_d)\n",
    "        opt_indices.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 33, 3, 33, 20, 10, 3, 20, 10, 5, 10, 33, 33, 20, 15, 15],\n",
       " [2, 4, 5, 8, 9, 11, 12, 13, 14, 15, 16, 19, 20, 21, 24, 26])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_ds, opt_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44525306814536875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr_np(ahmet_round(oofs, opt_ds, opt_indices), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4436432395133682"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oofs_alt = oofs.copy()\n",
    "train[\"eng\"] = train[\"url\"].apply(lambda x: x.startswith(\"http://english.\") or x.startswith(\"http://ell.\"))\n",
    "oofs_alt[np.where((~train[\"eng\"]).values)[0], 19] = 0\n",
    "spearmanr_np(ahmet_round(oofs_alt, opt_ds, opt_indices), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41031797952499016"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr_np(oofs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42529347523953587"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr_np(round_preds(oofs, high_num=3), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.432655762732102"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr_np(ahmet_round(oofs), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping is necessary or we will get an error\n",
    "sample_submission.loc[:, 'question_asker_intent_understanding':] = np.clip(preds, 0.00001, 0.999999)\n",
    "sample_submission.to_csv('subs/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.822700</td>\n",
       "      <td>0.606757</td>\n",
       "      <td>0.336699</td>\n",
       "      <td>0.420720</td>\n",
       "      <td>0.533662</td>\n",
       "      <td>0.399967</td>\n",
       "      <td>0.682947</td>\n",
       "      <td>0.691007</td>\n",
       "      <td>0.708347</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.707284</td>\n",
       "      <td>0.785448</td>\n",
       "      <td>0.024199</td>\n",
       "      <td>0.367336</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.098493</td>\n",
       "      <td>0.180147</td>\n",
       "      <td>0.787721</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.824019</td>\n",
       "      <td>0.573177</td>\n",
       "      <td>0.206948</td>\n",
       "      <td>0.738640</td>\n",
       "      <td>0.701363</td>\n",
       "      <td>0.320697</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.770751</td>\n",
       "      <td>0.635181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.462724</td>\n",
       "      <td>0.279110</td>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.673089</td>\n",
       "      <td>0.642312</td>\n",
       "      <td>0.868605</td>\n",
       "      <td>0.439451</td>\n",
       "      <td>0.352340</td>\n",
       "      <td>0.046728</td>\n",
       "      <td>0.020105</td>\n",
       "      <td>0.474518</td>\n",
       "      <td>0.201602</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.884329</td>\n",
       "      <td>0.326320</td>\n",
       "      <td>0.073492</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.223245</td>\n",
       "      <td>0.758264</td>\n",
       "      <td>0.474525</td>\n",
       "      <td>0.849371</td>\n",
       "      <td>0.918302</td>\n",
       "      <td>0.577462</td>\n",
       "      <td>0.940548</td>\n",
       "      <td>0.220579</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>0.584879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.703702</td>\n",
       "      <td>0.576812</td>\n",
       "      <td>0.033531</td>\n",
       "      <td>0.614484</td>\n",
       "      <td>0.819365</td>\n",
       "      <td>0.901766</td>\n",
       "      <td>0.514962</td>\n",
       "      <td>0.435678</td>\n",
       "      <td>0.285654</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.288072</td>\n",
       "      <td>0.712988</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.068587</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>0.174573</td>\n",
       "      <td>0.157993</td>\n",
       "      <td>0.741391</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.663175</td>\n",
       "      <td>0.624018</td>\n",
       "      <td>0.282989</td>\n",
       "      <td>0.808603</td>\n",
       "      <td>0.807562</td>\n",
       "      <td>0.437865</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>0.071098</td>\n",
       "      <td>0.811514</td>\n",
       "      <td>0.576552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.552414</td>\n",
       "      <td>0.160868</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.598914</td>\n",
       "      <td>0.658376</td>\n",
       "      <td>0.866602</td>\n",
       "      <td>0.404639</td>\n",
       "      <td>0.249985</td>\n",
       "      <td>0.197994</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.560950</td>\n",
       "      <td>0.140891</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.793897</td>\n",
       "      <td>0.311723</td>\n",
       "      <td>0.633305</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.424982</td>\n",
       "      <td>0.801611</td>\n",
       "      <td>0.586616</td>\n",
       "      <td>0.863023</td>\n",
       "      <td>0.915087</td>\n",
       "      <td>0.642099</td>\n",
       "      <td>0.819072</td>\n",
       "      <td>0.338838</td>\n",
       "      <td>0.659485</td>\n",
       "      <td>0.647182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.770276</td>\n",
       "      <td>0.268402</td>\n",
       "      <td>0.044636</td>\n",
       "      <td>0.811169</td>\n",
       "      <td>0.732296</td>\n",
       "      <td>0.874867</td>\n",
       "      <td>0.672194</td>\n",
       "      <td>0.692984</td>\n",
       "      <td>0.167548</td>\n",
       "      <td>0.026423</td>\n",
       "      <td>0.347347</td>\n",
       "      <td>0.538915</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.022899</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>0.085386</td>\n",
       "      <td>0.173449</td>\n",
       "      <td>0.172238</td>\n",
       "      <td>0.576171</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.336878</td>\n",
       "      <td>0.730333</td>\n",
       "      <td>0.550887</td>\n",
       "      <td>0.871366</td>\n",
       "      <td>0.866420</td>\n",
       "      <td>0.620386</td>\n",
       "      <td>0.227170</td>\n",
       "      <td>0.211454</td>\n",
       "      <td>0.721060</td>\n",
       "      <td>0.609149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.822700                0.606757   \n",
       "1     46                             0.462724                0.279110   \n",
       "2     70                             0.703702                0.576812   \n",
       "3    132                             0.552414                0.160868   \n",
       "4    200                             0.770276                0.268402   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.336699                      0.420720   \n",
       "1                 0.010432                      0.673089   \n",
       "2                 0.033531                      0.614484   \n",
       "3                 0.006397                      0.598914   \n",
       "4                 0.044636                      0.811169   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.533662                               0.399967   \n",
       "1               0.642312                               0.868605   \n",
       "2               0.819365                               0.901766   \n",
       "3               0.658376                               0.866602   \n",
       "4               0.732296                               0.874867   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.682947                       0.691007   \n",
       "1                         0.439451                       0.352340   \n",
       "2                         0.514962                       0.435678   \n",
       "3                         0.404639                       0.249985   \n",
       "4                         0.672194                       0.692984   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  \\\n",
       "0               0.708347                        0.004008   \n",
       "1               0.046728                        0.020105   \n",
       "2               0.285654                        0.005296   \n",
       "3               0.197994                        0.012324   \n",
       "4               0.167548                        0.026423   \n",
       "\n",
       "   question_opinion_seeking  question_type_choice  question_type_compare  \\\n",
       "0                  0.707284              0.785448               0.024199   \n",
       "1                  0.474518              0.201602               0.004156   \n",
       "2                  0.288072              0.712988               0.024532   \n",
       "3                  0.560950              0.140891               0.002595   \n",
       "4                  0.347347              0.538915               0.007729   \n",
       "\n",
       "   question_type_consequence  question_type_definition  question_type_entity  \\\n",
       "0                   0.367336                  0.005207              0.024593   \n",
       "1                   0.000762                  0.001017              0.013282   \n",
       "2                   0.068587                  0.001348              0.007341   \n",
       "3                   0.005380                  0.000537              0.003947   \n",
       "4                   0.022899                  0.008389              0.085386   \n",
       "\n",
       "   question_type_instructions  question_type_procedure  \\\n",
       "0                    0.098493                 0.180147   \n",
       "1                    0.884329                 0.326320   \n",
       "2                    0.174573                 0.157993   \n",
       "3                    0.793897                 0.311723   \n",
       "4                    0.173449                 0.172238   \n",
       "\n",
       "   question_type_reason_explanation  question_type_spelling  \\\n",
       "0                          0.787721                0.000775   \n",
       "1                          0.073492                0.000166   \n",
       "2                          0.741391                0.000702   \n",
       "3                          0.633305                0.000127   \n",
       "4                          0.576171                0.003145   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.824019        0.573177                     0.206948   \n",
       "1               0.223245        0.758264                     0.474525   \n",
       "2               0.663175        0.624018                     0.282989   \n",
       "3               0.424982        0.801611                     0.586616   \n",
       "4               0.336878        0.730333                     0.550887   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.738640          0.701363             0.320697   \n",
       "1          0.849371          0.918302             0.577462   \n",
       "2          0.808603          0.807562             0.437865   \n",
       "3          0.863023          0.915087             0.642099   \n",
       "4          0.871366          0.866420             0.620386   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.035148               0.045657   \n",
       "1                  0.940548               0.220579   \n",
       "2                  0.066814               0.071098   \n",
       "3                  0.819072               0.338838   \n",
       "4                  0.227170               0.211454   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.770751             0.635181  \n",
       "1                        0.044803             0.584879  \n",
       "2                        0.811514             0.576552  \n",
       "3                        0.659485             0.647182  \n",
       "4                        0.721060             0.609149  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(oofs, columns=TARGETS).to_csv(f'oofs/{model_name}_oofs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.825208</td>\n",
       "      <td>0.732010</td>\n",
       "      <td>0.285660</td>\n",
       "      <td>0.595585</td>\n",
       "      <td>0.526514</td>\n",
       "      <td>0.457385</td>\n",
       "      <td>0.577916</td>\n",
       "      <td>0.504816</td>\n",
       "      <td>0.313085</td>\n",
       "      <td>0.005759</td>\n",
       "      <td>0.739529</td>\n",
       "      <td>0.386783</td>\n",
       "      <td>0.530199</td>\n",
       "      <td>0.077227</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.190029</td>\n",
       "      <td>0.115815</td>\n",
       "      <td>0.561065</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.754423</td>\n",
       "      <td>0.865115</td>\n",
       "      <td>0.576628</td>\n",
       "      <td>0.929815</td>\n",
       "      <td>0.898261</td>\n",
       "      <td>0.709310</td>\n",
       "      <td>0.107572</td>\n",
       "      <td>0.100761</td>\n",
       "      <td>0.881541</td>\n",
       "      <td>0.705921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.907463</td>\n",
       "      <td>0.811366</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>0.572271</td>\n",
       "      <td>0.920137</td>\n",
       "      <td>0.734813</td>\n",
       "      <td>0.508455</td>\n",
       "      <td>0.657140</td>\n",
       "      <td>0.265344</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.279264</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>0.919784</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.515191</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>0.034207</td>\n",
       "      <td>0.057396</td>\n",
       "      <td>0.368510</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.823952</td>\n",
       "      <td>0.579780</td>\n",
       "      <td>0.317529</td>\n",
       "      <td>0.719288</td>\n",
       "      <td>0.761281</td>\n",
       "      <td>0.377926</td>\n",
       "      <td>0.020907</td>\n",
       "      <td>0.039386</td>\n",
       "      <td>0.576733</td>\n",
       "      <td>0.825547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626358</td>\n",
       "      <td>0.188460</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.765594</td>\n",
       "      <td>0.759052</td>\n",
       "      <td>0.858059</td>\n",
       "      <td>0.509447</td>\n",
       "      <td>0.318602</td>\n",
       "      <td>0.180395</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.399277</td>\n",
       "      <td>0.314772</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.431418</td>\n",
       "      <td>0.649472</td>\n",
       "      <td>0.211830</td>\n",
       "      <td>0.115748</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.492699</td>\n",
       "      <td>0.833217</td>\n",
       "      <td>0.570151</td>\n",
       "      <td>0.901700</td>\n",
       "      <td>0.889291</td>\n",
       "      <td>0.687920</td>\n",
       "      <td>0.552265</td>\n",
       "      <td>0.262810</td>\n",
       "      <td>0.483859</td>\n",
       "      <td>0.742231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.769974</td>\n",
       "      <td>0.685762</td>\n",
       "      <td>0.261486</td>\n",
       "      <td>0.637310</td>\n",
       "      <td>0.705681</td>\n",
       "      <td>0.742294</td>\n",
       "      <td>0.610959</td>\n",
       "      <td>0.647968</td>\n",
       "      <td>0.257515</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.371961</td>\n",
       "      <td>0.955387</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.011708</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.030266</td>\n",
       "      <td>0.136437</td>\n",
       "      <td>0.527152</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.868479</td>\n",
       "      <td>0.756458</td>\n",
       "      <td>0.787489</td>\n",
       "      <td>0.810025</td>\n",
       "      <td>0.857945</td>\n",
       "      <td>0.722660</td>\n",
       "      <td>0.052692</td>\n",
       "      <td>0.199028</td>\n",
       "      <td>0.880302</td>\n",
       "      <td>0.729794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.729064</td>\n",
       "      <td>0.701139</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>0.840436</td>\n",
       "      <td>0.906344</td>\n",
       "      <td>0.460270</td>\n",
       "      <td>0.433301</td>\n",
       "      <td>0.180305</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.235551</td>\n",
       "      <td>0.631419</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.758189</td>\n",
       "      <td>0.316464</td>\n",
       "      <td>0.198534</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.778453</td>\n",
       "      <td>0.712640</td>\n",
       "      <td>0.427886</td>\n",
       "      <td>0.796751</td>\n",
       "      <td>0.866208</td>\n",
       "      <td>0.585283</td>\n",
       "      <td>0.908294</td>\n",
       "      <td>0.253409</td>\n",
       "      <td>0.042249</td>\n",
       "      <td>0.551642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>0.896938</td>\n",
       "      <td>0.382275</td>\n",
       "      <td>0.174954</td>\n",
       "      <td>0.855542</td>\n",
       "      <td>0.686108</td>\n",
       "      <td>0.680277</td>\n",
       "      <td>0.718314</td>\n",
       "      <td>0.760258</td>\n",
       "      <td>0.513592</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.559924</td>\n",
       "      <td>0.894836</td>\n",
       "      <td>0.125911</td>\n",
       "      <td>0.077690</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.140240</td>\n",
       "      <td>0.018619</td>\n",
       "      <td>0.044556</td>\n",
       "      <td>0.487116</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.710893</td>\n",
       "      <td>0.845430</td>\n",
       "      <td>0.642838</td>\n",
       "      <td>0.933837</td>\n",
       "      <td>0.890986</td>\n",
       "      <td>0.667456</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>0.077821</td>\n",
       "      <td>0.865178</td>\n",
       "      <td>0.733415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>0.890261</td>\n",
       "      <td>0.516149</td>\n",
       "      <td>0.080136</td>\n",
       "      <td>0.576387</td>\n",
       "      <td>0.496637</td>\n",
       "      <td>0.353973</td>\n",
       "      <td>0.786596</td>\n",
       "      <td>0.819998</td>\n",
       "      <td>0.035577</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.724266</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>0.210712</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.762151</td>\n",
       "      <td>0.836844</td>\n",
       "      <td>0.586783</td>\n",
       "      <td>0.914491</td>\n",
       "      <td>0.939245</td>\n",
       "      <td>0.612630</td>\n",
       "      <td>0.763741</td>\n",
       "      <td>0.362578</td>\n",
       "      <td>0.367470</td>\n",
       "      <td>0.870759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.222845</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.660493</td>\n",
       "      <td>0.716996</td>\n",
       "      <td>0.899986</td>\n",
       "      <td>0.409190</td>\n",
       "      <td>0.266355</td>\n",
       "      <td>0.185233</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.486928</td>\n",
       "      <td>0.366203</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.853027</td>\n",
       "      <td>0.386642</td>\n",
       "      <td>0.256628</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.322818</td>\n",
       "      <td>0.362327</td>\n",
       "      <td>0.273115</td>\n",
       "      <td>0.569764</td>\n",
       "      <td>0.716263</td>\n",
       "      <td>0.296554</td>\n",
       "      <td>0.603217</td>\n",
       "      <td>0.205985</td>\n",
       "      <td>0.416264</td>\n",
       "      <td>0.175751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>0.796093</td>\n",
       "      <td>0.426636</td>\n",
       "      <td>0.583988</td>\n",
       "      <td>0.357485</td>\n",
       "      <td>0.281736</td>\n",
       "      <td>0.171130</td>\n",
       "      <td>0.591611</td>\n",
       "      <td>0.696263</td>\n",
       "      <td>0.801729</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.889318</td>\n",
       "      <td>0.639978</td>\n",
       "      <td>0.161163</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>0.007028</td>\n",
       "      <td>0.042456</td>\n",
       "      <td>0.083135</td>\n",
       "      <td>0.295378</td>\n",
       "      <td>0.678197</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.865176</td>\n",
       "      <td>0.720334</td>\n",
       "      <td>0.484271</td>\n",
       "      <td>0.871150</td>\n",
       "      <td>0.861752</td>\n",
       "      <td>0.559136</td>\n",
       "      <td>0.034702</td>\n",
       "      <td>0.152802</td>\n",
       "      <td>0.853713</td>\n",
       "      <td>0.837048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>0.695196</td>\n",
       "      <td>0.720878</td>\n",
       "      <td>0.097479</td>\n",
       "      <td>0.281396</td>\n",
       "      <td>0.919191</td>\n",
       "      <td>0.624158</td>\n",
       "      <td>0.521804</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.703833</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.264180</td>\n",
       "      <td>0.107488</td>\n",
       "      <td>0.641186</td>\n",
       "      <td>0.021723</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.035254</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.957837</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.687473</td>\n",
       "      <td>0.791405</td>\n",
       "      <td>0.460346</td>\n",
       "      <td>0.860005</td>\n",
       "      <td>0.870402</td>\n",
       "      <td>0.532104</td>\n",
       "      <td>0.026325</td>\n",
       "      <td>0.045056</td>\n",
       "      <td>0.946765</td>\n",
       "      <td>0.718343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6079 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_asker_intent_understanding  question_body_critical  \\\n",
       "0                                0.825208                0.732010   \n",
       "1                                0.907463                0.811366   \n",
       "2                                0.626358                0.188460   \n",
       "3                                0.769974                0.685762   \n",
       "4                                0.729064                0.701139   \n",
       "...                                   ...                     ...   \n",
       "6074                             0.896938                0.382275   \n",
       "6075                             0.890261                0.516149   \n",
       "6076                             0.566372                0.222845   \n",
       "6077                             0.796093                0.426636   \n",
       "6078                             0.695196                0.720878   \n",
       "\n",
       "      question_conversational  question_expect_short_answer  \\\n",
       "0                    0.285660                      0.595585   \n",
       "1                    0.043013                      0.572271   \n",
       "2                    0.005228                      0.765594   \n",
       "3                    0.261486                      0.637310   \n",
       "4                    0.003882                      0.690619   \n",
       "...                       ...                           ...   \n",
       "6074                 0.174954                      0.855542   \n",
       "6075                 0.080136                      0.576387   \n",
       "6076                 0.003783                      0.660493   \n",
       "6077                 0.583988                      0.357485   \n",
       "6078                 0.097479                      0.281396   \n",
       "\n",
       "      question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                  0.526514                               0.457385   \n",
       "1                  0.920137                               0.734813   \n",
       "2                  0.759052                               0.858059   \n",
       "3                  0.705681                               0.742294   \n",
       "4                  0.840436                               0.906344   \n",
       "...                     ...                                    ...   \n",
       "6074               0.686108                               0.680277   \n",
       "6075               0.496637                               0.353973   \n",
       "6076               0.716996                               0.899986   \n",
       "6077               0.281736                               0.171130   \n",
       "6078               0.919191                               0.624158   \n",
       "\n",
       "      question_interestingness_others  question_interestingness_self  \\\n",
       "0                            0.577916                       0.504816   \n",
       "1                            0.508455                       0.657140   \n",
       "2                            0.509447                       0.318602   \n",
       "3                            0.610959                       0.647968   \n",
       "4                            0.460270                       0.433301   \n",
       "...                               ...                            ...   \n",
       "6074                         0.718314                       0.760258   \n",
       "6075                         0.786596                       0.819998   \n",
       "6076                         0.409190                       0.266355   \n",
       "6077                         0.591611                       0.696263   \n",
       "6078                         0.521804                       0.474219   \n",
       "\n",
       "      question_multi_intent  question_not_really_a_question  \\\n",
       "0                  0.313085                        0.005759   \n",
       "1                  0.265344                        0.001155   \n",
       "2                  0.180395                        0.001392   \n",
       "3                  0.257515                        0.001228   \n",
       "4                  0.180305                        0.001655   \n",
       "...                     ...                             ...   \n",
       "6074               0.513592                        0.001440   \n",
       "6075               0.035577                        0.012112   \n",
       "6076               0.185233                        0.002647   \n",
       "6077               0.801729                        0.001812   \n",
       "6078               0.703833                        0.000276   \n",
       "\n",
       "      question_opinion_seeking  question_type_choice  question_type_compare  \\\n",
       "0                     0.739529              0.386783               0.530199   \n",
       "1                     0.279264              0.116335               0.919784   \n",
       "2                     0.399277              0.314772               0.005709   \n",
       "3                     0.371961              0.955387               0.014987   \n",
       "4                     0.235551              0.631419               0.002775   \n",
       "...                        ...                   ...                    ...   \n",
       "6074                  0.559924              0.894836               0.125911   \n",
       "6075                  0.724266              0.011374               0.007933   \n",
       "6076                  0.486928              0.366203               0.001622   \n",
       "6077                  0.889318              0.639978               0.161163   \n",
       "6078                  0.264180              0.107488               0.641186   \n",
       "\n",
       "      question_type_consequence  question_type_definition  \\\n",
       "0                      0.077227                  0.012807   \n",
       "1                      0.004952                  0.515191   \n",
       "2                      0.002911                  0.000563   \n",
       "3                      0.029046                  0.011708   \n",
       "4                      0.001730                  0.002005   \n",
       "...                         ...                       ...   \n",
       "6074                   0.077690                  0.008024   \n",
       "6075                   0.022216                  0.000224   \n",
       "6076                   0.000821                  0.000351   \n",
       "6077                   0.113892                  0.007028   \n",
       "6078                   0.021723                  0.008805   \n",
       "\n",
       "      question_type_entity  question_type_instructions  \\\n",
       "0                 0.107073                    0.190029   \n",
       "1                 0.052519                    0.034207   \n",
       "2                 0.431418                    0.649472   \n",
       "3                 0.016541                    0.030266   \n",
       "4                 0.007261                    0.758189   \n",
       "...                    ...                         ...   \n",
       "6074              0.140240                    0.018619   \n",
       "6075              0.015318                    0.804781   \n",
       "6076              0.002010                    0.853027   \n",
       "6077              0.042456                    0.083135   \n",
       "6078              0.035254                    0.006299   \n",
       "\n",
       "      question_type_procedure  question_type_reason_explanation  \\\n",
       "0                    0.115815                          0.561065   \n",
       "1                    0.057396                          0.368510   \n",
       "2                    0.211830                          0.115748   \n",
       "3                    0.136437                          0.527152   \n",
       "4                    0.316464                          0.198534   \n",
       "...                       ...                               ...   \n",
       "6074                 0.044556                          0.487116   \n",
       "6075                 0.413051                          0.210712   \n",
       "6076                 0.386642                          0.256628   \n",
       "6077                 0.295378                          0.678197   \n",
       "6078                 0.022446                          0.957837   \n",
       "\n",
       "      question_type_spelling  question_well_written  answer_helpful  \\\n",
       "0                   0.003749               0.754423        0.865115   \n",
       "1                   0.008245               0.823952        0.579780   \n",
       "2                   0.000045               0.492699        0.833217   \n",
       "3                   0.000399               0.868479        0.756458   \n",
       "4                   0.000155               0.778453        0.712640   \n",
       "...                      ...                    ...             ...   \n",
       "6074                0.001367               0.710893        0.845430   \n",
       "6075                0.000153               0.762151        0.836844   \n",
       "6076                0.000036               0.322818        0.362327   \n",
       "6077                0.000493               0.865176        0.720334   \n",
       "6078                0.000123               0.687473        0.791405   \n",
       "\n",
       "      answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                        0.576628          0.929815          0.898261   \n",
       "1                        0.317529          0.719288          0.761281   \n",
       "2                        0.570151          0.901700          0.889291   \n",
       "3                        0.787489          0.810025          0.857945   \n",
       "4                        0.427886          0.796751          0.866208   \n",
       "...                           ...               ...               ...   \n",
       "6074                     0.642838          0.933837          0.890986   \n",
       "6075                     0.586783          0.914491          0.939245   \n",
       "6076                     0.273115          0.569764          0.716263   \n",
       "6077                     0.484271          0.871150          0.861752   \n",
       "6078                     0.460346          0.860005          0.870402   \n",
       "\n",
       "      answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0                0.709310                  0.107572               0.100761   \n",
       "1                0.377926                  0.020907               0.039386   \n",
       "2                0.687920                  0.552265               0.262810   \n",
       "3                0.722660                  0.052692               0.199028   \n",
       "4                0.585283                  0.908294               0.253409   \n",
       "...                   ...                       ...                    ...   \n",
       "6074             0.667456                  0.055694               0.077821   \n",
       "6075             0.612630                  0.763741               0.362578   \n",
       "6076             0.296554                  0.603217               0.205985   \n",
       "6077             0.559136                  0.034702               0.152802   \n",
       "6078             0.532104                  0.026325               0.045056   \n",
       "\n",
       "      answer_type_reason_explanation  answer_well_written  \n",
       "0                           0.881541             0.705921  \n",
       "1                           0.576733             0.825547  \n",
       "2                           0.483859             0.742231  \n",
       "3                           0.880302             0.729794  \n",
       "4                           0.042249             0.551642  \n",
       "...                              ...                  ...  \n",
       "6074                        0.865178             0.733415  \n",
       "6075                        0.367470             0.870759  \n",
       "6076                        0.416264             0.175751  \n",
       "6077                        0.853713             0.837048  \n",
       "6078                        0.946765             0.718343  \n",
       "\n",
       "[6079 rows x 30 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(oofs, columns=TARGETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
