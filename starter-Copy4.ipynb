{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "from radam import RAdam\n",
    "from text_data import TextDataset3, AugTextDataset\n",
    "from bert import CustomBert3, CustomBert5, CustomBert3b\n",
    "from learning import Learner\n",
    "from lr_finder import LRFinder\n",
    "from one_cycle import OneCycleLR\n",
    "from text_cleaning import clean_data\n",
    "from sentence_embed import get_use_embedding_features, get_distill_bert_features\n",
    "from create_features import get_dist_features, get_categorical_features\n",
    "from losses_metrics import spearmanr_torch, spearmanr_np, FocalLoss\n",
    "from inference import infer\n",
    "from eda import eda\n",
    "from common import *\n",
    "from utils.helpers import init_logger, init_seed\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "path = 'data/'\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
    "test = pd.read_csv(f'{path}test.csv').fillna(' ')\n",
    "train = pd.read_csv(f'{path}train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question'] = train['question_title'] + ' [SEP] ' + train['question_body']\n",
    "test['question'] = test['question_title'] + ' [SEP] ' + test['question_body']\n",
    "train['answer'] = train['question_title'] + ' [SEP] ' + train['answer']\n",
    "test['answer'] = test['question_title'] + ' [SEP] ' + test['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# init_seed()\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# ids_train = {}\n",
    "# ids_test = {}\n",
    "# num_aug = 4\n",
    "# max_seq_len = 512\n",
    "# for mode, df in [('train', train), ('test', test)]:\n",
    "#     for text in INPUTS:\n",
    "#         ids = {i: [] for i in range(num_aug+1)}\n",
    "#         for x in tqdm(df[text].values):\n",
    "#             if len(x.split(' ')) > 10:\n",
    "#                 augs = eda(x, alpha_sr=0.05, alpha_ri=0.05, alpha_rs=0.05, p_rd=0.05, num_aug=num_aug)[:-1]\n",
    "#                 augs = [x] + augs\n",
    "#             else:\n",
    "#                 augs = (num_aug + 1) * [x]\n",
    "#             encoded_inputs = []\n",
    "#             for i, aug in enumerate(augs):\n",
    "#                 encoded_inputs = tokenizer.encode_plus(\n",
    "#                     aug, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)['input_ids']\n",
    "#                 ids[i] += [encoded_inputs]\n",
    "#         if mode == 'train': ids_train[text] = [np.array(aug_ids) for aug_ids in ids.values()]\n",
    "#         else: ids_test[text]  = [np.array(aug_ids) for aug_ids in ids.values()]\n",
    "\n",
    "# for mode, ids in [('train', ids_train), ('test', ids_test)]:\n",
    "#     question_ids = {i: [] for i in range(num_aug+1)}\n",
    "#     for i in tqdm(range(len(ids['question_title'][0]))):\n",
    "#         for j, aug in enumerate(augs):\n",
    "#             qt_ids = ids['question_title'][j][i]\n",
    "#             qb_ids = ids['question_body'][j][i]\n",
    "#             q_ids = np.concatenate((qt_ids[qt_ids!=0], qb_ids[1:]))[:max_seq_len]\n",
    "#             question_ids[j].append(q_ids)\n",
    "#     if mode == 'train': ids_train['question'] = [np.array(aug_ids) for aug_ids in question_ids.values()]\n",
    "#     else: ids_test['question']  = [np.array(aug_ids) for aug_ids in question_ids.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f35f9ca8a24447a7d6d25802c26d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c0d3d2b06d40fc96f3ae801c07a892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d472678553946808c955ba73a5ff6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fc3326faa440a0b8255d82007081b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 27.1 s, sys: 214 ms, total: 27.3 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "ids_train = {}\n",
    "ids_test = {}\n",
    "max_seq_len = 512\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text in ['question', 'answer']:\n",
    "        ids = []\n",
    "        for x in tqdm(df[text].values):\n",
    "            encoded_inputs = tokenizer.encode_plus(\n",
    "                x, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)\n",
    "            ids.append(encoded_inputs['input_ids'])\n",
    "        if mode == 'train': ids_train[text] = np.array(ids)\n",
    "        else: ids_test[text] = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_host, test_host, host_dict, host_dict_reverse = get_categorical_features(train, test, 'host')\n",
    "train_category, test_category, category_dict, category_dict_reverse = \\\n",
    "    get_categorical_features(train, test, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_features_train = np.hstack([train_host.reshape(-1, 1), train_category.reshape(-1, 1)])\n",
    "cat_features_test = np.hstack([test_host.reshape(-1, 1), test_category.reshape(-1, 1)])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(cat_features_train)\n",
    "cat_features_train = ohe.transform(cat_features_train).toarray()\n",
    "cat_features_test = ohe.transform(cat_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[TARGETS].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10\n",
    "bs = 4\n",
    "TextDataset = TextDataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_test = 4\n",
    "test_loader = DataLoader(\n",
    "    TextDataset(cat_features_test, ids_test['question'], ids_test['answer'], test.index),\n",
    "    batch_size=bs_test, shuffle=False, num_workers=num_workers, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRankingLoss(nn.MSELoss):\n",
    "    def forward(self, input, target):\n",
    "        input = torch.sigmoid(input)\n",
    "        n = input.size(0)\n",
    "        n_pairs = n // 2\n",
    "        n_tot_pairs = n_pairs + (n % 2)\n",
    "        loss = 0\n",
    "        for i in range(n_pairs):\n",
    "            dp = input[2*i] - input[(2*i)+1]\n",
    "            dy = target[2*i] - target[(2*i)+1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "            \n",
    "        if n_tot_pairs > n_pairs:\n",
    "            dp = input[-2] - input[-1]\n",
    "            dy = target[-2] - target[-1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "        return loss\n",
    "    \n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=N_TARGETS*[1.0]):\n",
    "        super().__init__()\n",
    "        pos_weight = torch.Tensor(pos_weight).cuda()\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='mean', pos_weight=pos_weight)\n",
    "        self.mrl = MyRankingLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = (1. * self.bce(input, target) + 1. * self.mrl(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = 'cuda'\n",
    "n_epochs = 4\n",
    "grad_accum = 2\n",
    "weight_decay = 0.01\n",
    "model_name = 'double_distil_bert'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "early_stopping = None\n",
    "p_aug = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_param_groups(model, lr, weight_decay):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': weight_decay, 'lr': lr},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0, 'lr': lr}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr, weight_decay):\n",
    "    return transformers.AdamW(\n",
    "        get_optimizer_param_groups(model.head, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.q_bert, lr / 100, weight_decay)\n",
    "        + get_optimizer_param_groups(model.a_bert, lr / 100, weight_decay)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Tue Jan  7 23:38:07 2020\n",
      "CustomBert3(\n",
      "  (q_bert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (a_bert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): HeadNet2(\n",
      "    (lin): Sequential(\n",
      "      (0): Linear(in_features=1604, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_q): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_a): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (head_q): Linear(in_features=512, out_features=21, bias=True)\n",
      "    (head_a): Linear(in_features=512, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bddd464a82f40b0945de8ba2bb27a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58745d3a60694afba00f64225f8524ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/4 \t train : loss 0.42573 - spearmanr 0.19572\n",
      "epoch 0: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0a92b57b4b474c97f2395d3d12a022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/4 \t valid : loss 0.38383 - spearmanr 0.35621\n",
      "best model: epoch 0 - 0.35621\n",
      "epoch 1: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7d80767cbf4199b5c54ffe070c67ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/4 \t train : loss 0.36972 - spearmanr 0.37174\n",
      "epoch 1: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8aba0228801468daf6cbd86772996db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/4 \t valid : loss 0.37004 - spearmanr 0.39748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: epoch 1 - 0.39748\n",
      "epoch 2: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e420f483b787452783bead3ad3b2d9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/4 \t train : loss 0.35404 - spearmanr 0.4408\n",
      "epoch 2: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7341c7d2ff40efb207760687b45602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/4 \t valid : loss 0.36864 - spearmanr 0.42106\n",
      "best model: epoch 2 - 0.42106\n",
      "epoch 3: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761a4929e9b44f19afd5745e63451986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3/4 \t train : loss 0.3419 - spearmanr 0.49515\n",
      "epoch 3: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82283a29028445f7959301da5ccfb9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3/4 \t valid : loss 0.36913 - spearmanr 0.42472\n",
      "best model: epoch 3 - 0.42472\n",
      "TRAINING END: Best score achieved on epoch 3 - 0.42472\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d337a74d4b4ccbaa26ce72f65a2a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/double_distil_bert_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79b69d9e8e7416798b0a7cdfab1f9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 started at Tue Jan  7 23:57:11 2020\n",
      "epoch 0: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caaa8550d274250a577f5c80de8de55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_seed()\n",
    "folds = GroupKFold(n_splits=5).split(\n",
    "    X=train['question_body'], groups=train['question_body'])#KFold(n_splits=5, random_state=42).split(train)\n",
    "oofs = np.zeros((len(train), N_TARGETS))\n",
    "preds = np.zeros((len(test), N_TARGETS))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(folds):\n",
    "    print(f'Fold {fold_id + 1} started at {time.ctime()}')\n",
    "    train_loader = DataLoader(\n",
    "        TextDataset(cat_features_train, ids_train['question'], ids_train['answer'], train_index, #p_aug=p_aug,\n",
    "                       targets=y), batch_size=bs, shuffle=True, num_workers=num_workers, drop_last=False\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TextDataset(cat_features_train, ids_train['question'], ids_train['answer'], valid_index, #p_aug=0.0, \n",
    "                       targets=y), batch_size=bs, shuffle=False, num_workers=num_workers, drop_last=False\n",
    "    )\n",
    "    model = CustomBert3(256, cat_features_train.shape[1])\n",
    "    \n",
    "    if fold_id == 0:\n",
    "        print(model)\n",
    "        model = model.to(device)\n",
    "        optimizer = get_optimizer(model, lr, weight_decay)\n",
    "        lr_finder = LRFinder(n_iter=min(grad_accum*100, len(train_loader)), start_lr=1e-5, \n",
    "                             end_lr=1, device=device, grad_accum=grad_accum, divergence_factor=5)\n",
    "        lr_finder.find_lr(model, optimizer, train_loader, loss_fn)\n",
    "        plt.show()\n",
    "    \n",
    "    optimizer = get_optimizer(model, lr, weight_decay)\n",
    "    scheduler = OneCycleLR(optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "\n",
    "    learner = Learner(\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        n_epochs, \n",
    "        f'{model_name}_fold_{fold_id + 1}', \n",
    "        checkpoint_dir, \n",
    "        scheduler=scheduler, \n",
    "        metric_fns={'spearmanr': (spearmanr_torch, 'epoch_end')}, \n",
    "        monitor_metric='spearmanr',\n",
    "        minimize_score=False, \n",
    "        logger=None,\n",
    "        grad_accum=grad_accum,\n",
    "        early_stopping=early_stopping, \n",
    "        batch_step_scheduler=True\n",
    "    )\n",
    "    if (fold_id + 1) > 0: learner.train()\n",
    "    \n",
    "    oofs[valid_index] = infer(learner.model, valid_loader, learner.best_checkpoint_file, device)\n",
    "    \n",
    "    test_preds = infer(learner.model, test_loader, learner.best_checkpoint_file, device)\n",
    "    preds += test_preds / 5\n",
    "    \n",
    "    del learner, model, train_loader, valid_loader\n",
    "    gc.collect()\n",
    "    \n",
    "print(f'OOF score: {spearmanr_np(oofs, y)}')\n",
    "#0.4160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_round(x, num, dec=2):\n",
    "    return np.round(x / num, dec) * num\n",
    "\n",
    "def round_preds(preds, thres=0.0, low_dec=1, low_num=1, high_dec=2, high_num=3):\n",
    "    low_idx = preds < thres\n",
    "    new_preds = np.zeros_like(preds)\n",
    "    new_preds[low_idx] = my_round(preds[low_idx], low_num, low_dec)\n",
    "    new_preds[~low_idx] = my_round(preds[~low_idx], high_num, high_dec)\n",
    "    return new_preds\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "def spearmanr_np(preds, targets):\n",
    "    score = 0\n",
    "    for i in range(N_TARGETS):\n",
    "        score_i = spearmanr(preds[:, i], targets[:, i]).correlation\n",
    "        score += np.nan_to_num(score_i / N_TARGETS)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr_np(oofs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spearmanr_np(round_preds(oofs, high_num=3), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping is necessary or we will get an error\n",
    "sample_submission.loc[:, 'question_asker_intent_understanding':] = np.clip(preds, 0.00001, 0.999999)\n",
    "sample_submission.to_csv('subs/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
