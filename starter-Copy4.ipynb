{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-51cb9197ba3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistilBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "from radam import RAdam\n",
    "from text_data import TextDataset3, AugTextDataset\n",
    "from bert import CustomBert3, CustomBert5, CustomBert3b\n",
    "from learning import Learner\n",
    "from lr_finder import LRFinder\n",
    "from one_cycle import OneCycleLR\n",
    "from text_cleaning import clean_data\n",
    "from sentence_embed import get_use_embedding_features, get_distill_bert_features\n",
    "from create_features import get_dist_features, get_categorical_features\n",
    "from losses_metrics import spearmanr_torch, spearmanr_np, FocalLoss\n",
    "from inference import infer\n",
    "from eda import eda\n",
    "from common import *\n",
    "from utils.helpers import init_logger, init_seed\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "path = 'data/'\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
    "test = pd.read_csv(f'{path}test.csv').fillna(' ')\n",
    "train = pd.read_csv(f'{path}train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question'] = train['question_title'] + ' [SEP] ' + train['question_body']\n",
    "test['question'] = test['question_title'] + ' [SEP] ' + test['question_body']\n",
    "train['answer'] = train['question_title'] + ' [SEP] ' + train['answer']\n",
    "test['answer'] = test['question_title'] + ' [SEP] ' + test['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# init_seed()\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# ids_train = {}\n",
    "# ids_test = {}\n",
    "# num_aug = 4\n",
    "# max_seq_len = 512\n",
    "# for mode, df in [('train', train), ('test', test)]:\n",
    "#     for text in INPUTS:\n",
    "#         ids = {i: [] for i in range(num_aug+1)}\n",
    "#         for x in tqdm(df[text].values):\n",
    "#             if len(x.split(' ')) > 10:\n",
    "#                 augs = eda(x, alpha_sr=0.05, alpha_ri=0.05, alpha_rs=0.05, p_rd=0.05, num_aug=num_aug)[:-1]\n",
    "#                 augs = [x] + augs\n",
    "#             else:\n",
    "#                 augs = (num_aug + 1) * [x]\n",
    "#             encoded_inputs = []\n",
    "#             for i, aug in enumerate(augs):\n",
    "#                 encoded_inputs = tokenizer.encode_plus(\n",
    "#                     aug, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)['input_ids']\n",
    "#                 ids[i] += [encoded_inputs]\n",
    "#         if mode == 'train': ids_train[text] = [np.array(aug_ids) for aug_ids in ids.values()]\n",
    "#         else: ids_test[text]  = [np.array(aug_ids) for aug_ids in ids.values()]\n",
    "\n",
    "# for mode, ids in [('train', ids_train), ('test', ids_test)]:\n",
    "#     question_ids = {i: [] for i in range(num_aug+1)}\n",
    "#     for i in tqdm(range(len(ids['question_title'][0]))):\n",
    "#         for j, aug in enumerate(augs):\n",
    "#             qt_ids = ids['question_title'][j][i]\n",
    "#             qb_ids = ids['question_body'][j][i]\n",
    "#             q_ids = np.concatenate((qt_ids[qt_ids!=0], qb_ids[1:]))[:max_seq_len]\n",
    "#             question_ids[j].append(q_ids)\n",
    "#     if mode == 'train': ids_train['question'] = [np.array(aug_ids) for aug_ids in question_ids.values()]\n",
    "#     else: ids_test['question']  = [np.array(aug_ids) for aug_ids in question_ids.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6196cc0be474245868aaf538e9c3822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcba0c4e06704268a24f7fe89f6f3272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6079), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d2e3d1e5cd4f6595a1ff0902892228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83372a68c955467eb0b7e9c01bba1a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=476), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 27 s, sys: 187 ms, total: 27.2 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "ids_train = {}\n",
    "ids_test = {}\n",
    "max_seq_len = 512\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text in ['question', 'answer']:\n",
    "        ids = []\n",
    "        for x in tqdm(df[text].values):\n",
    "            encoded_inputs = tokenizer.encode_plus(\n",
    "                x, add_special_tokens=True, max_length=max_seq_len, pad_to_max_length=True)\n",
    "            ids.append(encoded_inputs['input_ids'])\n",
    "        if mode == 'train': ids_train[text] = np.array(ids)\n",
    "        else: ids_test[text] = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_host, test_host, host_dict, host_dict_reverse = get_categorical_features(train, test, 'host')\n",
    "train_category, test_category, category_dict, category_dict_reverse = \\\n",
    "    get_categorical_features(train, test, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_features_train = np.hstack([train_host.reshape(-1, 1), train_category.reshape(-1, 1)])\n",
    "cat_features_test = np.hstack([test_host.reshape(-1, 1), test_category.reshape(-1, 1)])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(cat_features_train)\n",
    "cat_features_train = ohe.transform(cat_features_train).toarray()\n",
    "cat_features_test = ohe.transform(cat_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[TARGETS].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10\n",
    "bs = 4\n",
    "TextDataset = TextDataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_test = 4\n",
    "test_loader = DataLoader(\n",
    "    TextDataset(cat_features_test, ids_test['question'], ids_test['answer'], test.index),\n",
    "    batch_size=bs_test, shuffle=False, num_workers=num_workers, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRankingLoss(nn.MSELoss):\n",
    "    def forward(self, input, target):\n",
    "        input = torch.sigmoid(input)\n",
    "        n = input.size(0)\n",
    "        n_pairs = n // 2\n",
    "        n_tot_pairs = n_pairs + (n % 2)\n",
    "        loss = 0\n",
    "        for i in range(n_pairs):\n",
    "            dp = input[2*i] - input[(2*i)+1]\n",
    "            dy = target[2*i] - target[(2*i)+1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "            \n",
    "        if n_tot_pairs > n_pairs:\n",
    "            dp = input[-2] - input[-1]\n",
    "            dy = target[-2] - target[-1]\n",
    "            loss += super().forward(dp, dy) / n_tot_pairs\n",
    "        return loss\n",
    "    \n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=N_TARGETS*[1.0]):\n",
    "        super().__init__()\n",
    "        pos_weight = torch.Tensor(pos_weight).cuda()\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='mean', pos_weight=pos_weight)\n",
    "        self.mrl = MyRankingLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = (1. * self.bce(input, target) + 1. * self.mrl(input, target))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = 'cuda'\n",
    "n_epochs = 4\n",
    "grad_accum = 2\n",
    "weight_decay = 0.01\n",
    "model_name = 'double_distil_bert'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "early_stopping = None\n",
    "n_folds = 10\n",
    "p_aug = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_param_groups(model, lr, weight_decay):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': weight_decay, 'lr': lr},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \n",
    "         'weight_decay': 0.0, 'lr': lr}\n",
    "    ]\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "\n",
    "def get_optimizer(model, lr, weight_decay):\n",
    "    return transformers.AdamW(\n",
    "        get_optimizer_param_groups(model.head, lr, weight_decay)\n",
    "        + get_optimizer_param_groups(model.q_bert, lr / 100, weight_decay)\n",
    "        + get_optimizer_param_groups(model.a_bert, lr / 100, weight_decay)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Wed Jan  8 07:12:31 2020\n",
      "CustomBert3(\n",
      "  (q_bert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (a_bert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): HeadNet2(\n",
      "    (lin): Sequential(\n",
      "      (0): Linear(in_features=1604, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_q): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lin_a): Sequential(\n",
      "      (0): Linear(in_features=836, out_features=256, bias=True)\n",
      "      (1): GELU()\n",
      "      (2): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (head_q): Linear(in_features=512, out_features=21, bias=True)\n",
      "    (head_a): Linear(in_features=512, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bfd82183b7406f96869b9f186dd426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0738a3d29c194abe9dd77002f000905b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/4 \t train : loss 0.42372 - spearmanr 0.19514\n",
      "epoch 0: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3475843c87ab47cf99a3be487e4159dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=152), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/4 \t valid : loss 0.37658 - spearmanr 0.37393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: epoch 0 - 0.37393\n",
      "epoch 1: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492ce85782a34546ac64d805130c116f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/4 \t train : loss 0.37057 - spearmanr 0.37115\n",
      "epoch 1: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc5dad55e9e4a5bb15c406799abe8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=152), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/4 \t valid : loss 0.36754 - spearmanr 0.40418\n",
      "best model: epoch 1 - 0.40418\n",
      "epoch 2: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1e441287094950a5c62288702aeb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/4 \t train : loss 0.35544 - spearmanr 0.44298\n",
      "epoch 2: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8874dcf37aa04cc697931a2d66715a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=152), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/4 \t valid : loss 0.36335 - spearmanr 0.4204\n",
      "best model: epoch 2 - 0.4204\n",
      "epoch 3: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2736df63c49349458a4b67f4311a9ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1368), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_seed()\n",
    "folds = GroupKFold(n_splits=n_folds).split(\n",
    "    X=train['question_body'], groups=train['question_body'])#KFold(n_splits=5, random_state=42).split(train)\n",
    "oofs = np.zeros((len(train), N_TARGETS))\n",
    "preds = np.zeros((len(test), N_TARGETS))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(folds):\n",
    "    print(f'Fold {fold_id + 1} started at {time.ctime()}')\n",
    "    train_loader = DataLoader(\n",
    "        TextDataset(cat_features_train, ids_train['question'], ids_train['answer'], train_index, #p_aug=p_aug,\n",
    "                       targets=y), batch_size=bs, shuffle=True, num_workers=num_workers, drop_last=False\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TextDataset(cat_features_train, ids_train['question'], ids_train['answer'], valid_index, #p_aug=0.0, \n",
    "                       targets=y), batch_size=bs, shuffle=False, num_workers=num_workers, drop_last=False\n",
    "    )\n",
    "    model = CustomBert3(256, cat_features_train.shape[1])\n",
    "    \n",
    "    if fold_id == 0:\n",
    "        print(model)\n",
    "        model = model.to(device)\n",
    "        optimizer = get_optimizer(model, lr, weight_decay)\n",
    "        lr_finder = LRFinder(n_iter=min(grad_accum*100, len(train_loader)), start_lr=1e-5, \n",
    "                             end_lr=1, device=device, grad_accum=grad_accum, divergence_factor=5)\n",
    "        lr_finder.find_lr(model, optimizer, train_loader, loss_fn)\n",
    "        plt.show()\n",
    "    \n",
    "    optimizer = get_optimizer(model, lr, weight_decay)\n",
    "    scheduler = OneCycleLR(optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "\n",
    "    learner = Learner(\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        n_epochs, \n",
    "        f'{model_name}_fold_{fold_id + 1}', \n",
    "        checkpoint_dir, \n",
    "        scheduler=scheduler, \n",
    "        metric_fns={'spearmanr': (spearmanr_torch, 'epoch_end')}, \n",
    "        monitor_metric='spearmanr',\n",
    "        minimize_score=False, \n",
    "        logger=None,\n",
    "        grad_accum=grad_accum,\n",
    "        early_stopping=early_stopping, \n",
    "        batch_step_scheduler=True\n",
    "    )\n",
    "    if (fold_id + 1) > 0: learner.train()\n",
    "    \n",
    "    oofs[valid_index] = infer(learner.model, valid_loader, learner.best_checkpoint_file, device)\n",
    "    \n",
    "    test_preds = infer(learner.model, test_loader, learner.best_checkpoint_file, device)\n",
    "    preds += test_preds / n_folds\n",
    "    \n",
    "    del learner, model, train_loader, valid_loader\n",
    "    gc.collect()\n",
    "    \n",
    "print(f'OOF score: {spearmanr_np(oofs, y)}')\n",
    "#0.4160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_round(x, num, dec=2):\n",
    "    return np.round(x / num, dec) * num\n",
    "\n",
    "def round_preds(preds, thres=0.0, low_dec=1, low_num=1, high_dec=2, high_num=3):\n",
    "    low_idx = preds < thres\n",
    "    new_preds = np.zeros_like(preds)\n",
    "    new_preds[low_idx] = my_round(preds[low_idx], low_num, low_dec)\n",
    "    new_preds[~low_idx] = my_round(preds[~low_idx], high_num, high_dec)\n",
    "    return new_preds\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "def spearmanr_np(preds, targets):\n",
    "    score = 0\n",
    "    for i in range(N_TARGETS):\n",
    "        score_i = spearmanr(preds[:, i], targets[:, i]).correlation\n",
    "        score += np.nan_to_num(score_i / N_TARGETS)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr_np(oofs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spearmanr_np(round_preds(oofs, high_num=3), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping is necessary or we will get an error\n",
    "sample_submission.loc[:, 'question_asker_intent_understanding':] = np.clip(preds, 0.00001, 0.999999)\n",
    "sample_submission.to_csv('subs/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
