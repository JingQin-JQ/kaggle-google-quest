{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import gc\n",
    "from urllib.parse import urlparse\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "from radam import RAdam\n",
    "from text_data import TextDataset2, TextDataset3\n",
    "from bert import CustomBert, HeadNet\n",
    "from learning import Learner\n",
    "from lr_finder import LRFinder\n",
    "from one_cycle import OneCycleLR\n",
    "from text_cleaning import clean_data\n",
    "from sentence_embed import get_use_embedding_features, get_distill_bert_features\n",
    "from create_features import get_dist_features, get_categorical_features\n",
    "from losses_metrics import spearmanr_torch, spearmanr_np\n",
    "from inference import infer\n",
    "from common import *\n",
    "from utils.helpers import init_logger, init_seed\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "path = 'data/'\n",
    "sample_submission = pd.read_csv(f'{path}sample_submission.csv')\n",
    "test = pd.read_csv(f'{path}test.csv').fillna(' ')\n",
    "train = pd.read_csv(f'{path}train.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = clean_data(train, INPUTS)\n",
    "test = clean_data(test, INPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 17.3 ms, total: 20.5 s\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "ids_train = {}\n",
    "ids_test = {}\n",
    "max_seq_len = 512\n",
    "for mode, df in [('train', train), ('test', test)]:\n",
    "    for text in INPUTS:\n",
    "        ids = []\n",
    "        for x in df[text].values:\n",
    "            x = \" \".join(x.strip().split()[:300])\n",
    "            tok = tokenizer.encode(x, add_special_tokens=True)\n",
    "            ids.append(tok[:max_seq_len])\n",
    "        ids = np.array([i + [0] * (max_seq_len - len(i)) for i in ids])\n",
    "        if mode == 'train': ids_train[text] = ids\n",
    "        else: ids_test[text] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 64.2 ms, total: 1.19 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distill_bert_feature_path = 'proc_data/distill_bert_features/'\n",
    "bert_features_train, bert_features_test = get_distill_bert_features(\n",
    "    train, test, ['question_body', 'answer'], 64, distill_bert_feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 27.6 ms, total: 1.21 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "use_feature_path = 'proc_data/use_embedding_features/'\n",
    "embedding_train, embedding_test = get_use_embedding_features(train, test, INPUTS, use_feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 16.3 ms, total: 1.14 s\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dist_features_train, dist_features_test  = get_dist_features(embedding_train, embedding_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_host, test_host, host_dict, host_dict_reverse = get_categorical_features(train, test, 'host')\n",
    "train_category, test_category, category_dict, category_dict_reverse = \\\n",
    "    get_categorical_features(train, test, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cat_features_train = np.hstack([train_host.reshape(-1, 1), train_category.reshape(-1, 1)])\n",
    "cat_features_test = np.hstack([test_host.reshape(-1, 1), test_category.reshape(-1, 1)])\n",
    "merged = np.vstack([cat_features_train, cat_features_test])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(merged)\n",
    "\n",
    "cat_features_train = ohe.transform(cat_features_train).toarray()\n",
    "cat_features_test = ohe.transform(cat_features_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features_train = np.hstack([cat_features_train, dist_features_train])\n",
    "x_features_test = np.hstack([cat_features_test, dist_features_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[TARGETS].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 10\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_test = 4\n",
    "test_loader = DataLoader(\n",
    "    TextDataset2(x_features_test, embedding_test['question_body_embedding'], \n",
    "                 embedding_test['answer_embedding'], embedding_test['question_title_embedding'], \n",
    "                 ids_test['question_body'], ids_test['answer'], ids_test['question_title'], test.index),\n",
    "    batch_size=bs_test, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "lr2 = 0.00001\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda')\n",
    "n_epochs = 6\n",
    "model_name = 'distil_bert'\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "early_stopping = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr):\n",
    "    return optim.Adam([#params=model.parameters(), lr=lr)#[\n",
    "                {'params': model.head.parameters(), 'lr': lr},\n",
    "                {'params': model.q_bert.parameters(), 'lr': lr/100},\n",
    "                {'params': model.a_bert.parameters(), 'lr': lr/100}\n",
    "            ])\n",
    "\n",
    "def get_optimizer2(model, lr):\n",
    "    return RAdam(params=model.parameters(), lr=lr)#[\n",
    "                #{'params': model.head.parameters(), 'lr': lr},\n",
    "                #{'params': model.q_bert.parameters(), 'lr': lr/10},\n",
    "                #{'params': model.a_bert.parameters(), 'lr': lr/10}\n",
    "            #])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Fri Dec  6 21:00:41 2019\n",
      "Starting inference for model: checkpoints/distil_bert_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af8a463d36d40dcbfe601c284ef862f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/distil_bert_fold_1_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7714f69de10340a2b5d9e87fd779d575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 started at Fri Dec  6 21:01:15 2019\n",
      "Starting inference for model: checkpoints/distil_bert_fold_2_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66ac51f04d141c8a99ea3c4c9a799c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/distil_bert_fold_2_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825e90eeddaa4e71840c33b497e534c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 started at Fri Dec  6 21:01:52 2019\n",
      "Starting inference for model: checkpoints/distil_bert_fold_3_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d5909b7d184607ad0bd25cba09a54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/distil_bert_fold_3_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d41cc136f94d75ab6d5e445827e586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 started at Fri Dec  6 21:02:24 2019\n",
      "Starting inference for model: checkpoints/distil_bert_fold_4_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0e2c9f4524438e91db19d2a1088416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/distil_bert_fold_4_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d624fb10284954a8559a85119fa01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5 started at Fri Dec  6 21:02:56 2019\n",
      "epoch 0: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e71ec2c532344888e3964bb504d4576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/6 \t train : loss 0.46603 - spearmanr 0.11774\n",
      "epoch 0: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8608fda5a6b847c5a6d11ec323d399e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/6 \t valid : loss 0.3936 - spearmanr 0.31171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/robin/anaconda3/envs/GoogleQuest/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: epoch 0 - 0.31171\n",
      "epoch 1: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d000999ac149d5a31afd7b8468386e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/6 \t train : loss 0.38169 - spearmanr 0.32855\n",
      "epoch 1: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf43c14f83ea45329b545b1625514e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/6 \t valid : loss 0.37211 - spearmanr 0.3863\n",
      "best model: epoch 1 - 0.3863\n",
      "epoch 2: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b272f7e146a4ea68ed34f080ea681ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/6 \t train : loss 0.36349 - spearmanr 0.4001\n",
      "epoch 2: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce03b3eb4b2c459abe4d55af643c28bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2/6 \t valid : loss 0.36823 - spearmanr 0.40159\n",
      "best model: epoch 2 - 0.40159\n",
      "epoch 3: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431ce7ae0db84371babfe22165b8ffe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3/6 \t train : loss 0.35291 - spearmanr 0.43939\n",
      "epoch 3: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b48f39985c4a5fb079335b5df22638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3/6 \t valid : loss 0.36526 - spearmanr 0.40574\n",
      "best model: epoch 3 - 0.40574\n",
      "epoch 4: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bc1efaa8c04652a94532fdeaf8d8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4/6 \t train : loss 0.34338 - spearmanr 0.476\n",
      "epoch 4: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb7f6f07d1e4e989317c41916df56be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4/6 \t valid : loss 0.36615 - spearmanr 0.40749\n",
      "best model: epoch 4 - 0.40749\n",
      "epoch 5: \t Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4d4d31b4dd46edbcbdf9a540ba5e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5/6 \t train : loss 0.33732 - spearmanr 0.49818\n",
      "epoch 5: \t Start validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409b04485aa8418e98e049df7c350664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5/6 \t valid : loss 0.36676 - spearmanr 0.40648\n",
      "model not improved for 1 epochs\n",
      "TRAINING END: Best score achieved on epoch 4 - 0.40749\n",
      "Starting inference for model: checkpoints/distil_bert_fold_5_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7820ad9006ab4b6a926986eafc390d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=304), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for model: checkpoints/distil_bert_fold_5_best.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1710480993d045afb1a9d86f0c25d06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=119), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOF score: 0.40494972787028266\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, random_state=42)\n",
    "oofs = np.zeros((len(train), N_TARGETS))\n",
    "preds = np.zeros((len(test), N_TARGETS))\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(folds.split(train)):\n",
    "    print(f'Fold {fold_id + 1} started at {time.ctime()}')\n",
    "#     train_loader = DataLoader(\n",
    "#         TextDataset3(x_features_train, embedding_train['question_body_embedding'], \n",
    "#                      embedding_train['answer_embedding'], embedding_train['question_title_embedding'], \n",
    "#                      bert_features_train['question_body'], bert_features_train['answer'],\n",
    "#                      train_index, y),\n",
    "#         batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True\n",
    "#     )\n",
    "#     valid_loader = DataLoader(\n",
    "#         TextDataset3(x_features_train, embedding_train['question_body_embedding'], \n",
    "#                      embedding_train['answer_embedding'], embedding_train['question_title_embedding'], \n",
    "#                      bert_features_train['question_body'], bert_features_train['answer'], \n",
    "#                      valid_index, y),\n",
    "#         batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "#     )\n",
    "        \n",
    "#     model = HeadNet(n_h=256)\n",
    "#     model.to(device)\n",
    "    train_loader = DataLoader(\n",
    "        TextDataset2(x_features_train, embedding_train['question_body_embedding'], \n",
    "                     embedding_train['answer_embedding'], embedding_train['question_title_embedding'], \n",
    "                     ids_train['question_body'], ids_train['answer'], ids_train['question_title'], \n",
    "                     train_index, y),\n",
    "        batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TextDataset2(x_features_train, embedding_train['question_body_embedding'], \n",
    "                     embedding_train['answer_embedding'], embedding_train['question_title_embedding'], \n",
    "                     ids_train['question_body'], ids_train['answer'], ids_train['question_title'], \n",
    "                     valid_index, y),\n",
    "        batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "        \n",
    "    model = CustomBert(256)\n",
    "    \n",
    "#     if fold_id == 0:\n",
    "#         optimizer = get_optimizer(model, lr)\n",
    "#         lr_finder = LRFinder(n_iter=800, start_lr=1e-5, end_lr=1, device=device, grad_accum=8)\n",
    "#         lr_finder.find_lr(model, optimizer, train_loader, loss_fn)\n",
    "#         plt.show()\n",
    "    \n",
    "    optimizer = get_optimizer(model, lr)\n",
    "    #scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1)\n",
    "    scheduler = OneCycleLR(optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "\n",
    "    learner = Learner(\n",
    "        model, \n",
    "        optimizer, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        device, \n",
    "        n_epochs, \n",
    "        f'{model_name}_fold_{fold_id + 1}', \n",
    "        checkpoint_dir, \n",
    "        scheduler=scheduler, \n",
    "        metric_fns={'spearmanr': (spearmanr_torch, 'epoch_end')}, \n",
    "        monitor_metric='spearmanr',\n",
    "        minimize_score=False, \n",
    "        logger=None,\n",
    "        grad_accum=8,\n",
    "        early_stopping=early_stopping, \n",
    "        batch_step_scheduler=True\n",
    "    )\n",
    "    if fold_id + 1 > 4: learner.train()\n",
    "    \n",
    "    # 2nd stage\n",
    "    \n",
    "#     train_loader = DataLoader(\n",
    "#         TextDataset2(x_features_train, embedding_train['question_body_embedding'], \n",
    "#                      embedding_train['answer_embedding'], embedding_train['question_title_embedding'], \n",
    "#                      ids_train['question_body'], ids_train['answer'], ids_train['question_title'], \n",
    "#                      train_index, y),\n",
    "#         batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True\n",
    "#     )\n",
    "#     valid_loader = DataLoader(\n",
    "#         TextDataset2(x_features_train, embedding_train['question_body_embedding'], \n",
    "#                      embedding_train['answer_embedding'], embedding_train['question_title_embedding'], \n",
    "#                      ids_train['question_body'], ids_train['answer'], ids_train['question_title'], \n",
    "#                      valid_index, y),\n",
    "#         batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "#     )\n",
    "#     learner.train_loader = train_loader\n",
    "#     learner.valid_loader = valid_loader\n",
    "        \n",
    "#     model = CustomBert(256)\n",
    "    \n",
    "#     learner.load_best_model()\n",
    "#     model.head = learner.model\n",
    "#     learner.model = model\n",
    "#     learner.optimizer = get_optimizer2(model, lr2)\n",
    "#     learner.scheduler = OneCycleLR(learner.optimizer, n_epochs=n_epochs, n_batches=len(train_loader))\n",
    "# #     learner.scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1)\n",
    "# #     learner.early_stopping = 5\n",
    "# #     learner.n_epochs *= 2\n",
    "# #     learner.batch_step_scheduler = False\n",
    "#     learner.train()\n",
    "    \n",
    "    oofs[valid_index] = infer(learner.model, valid_loader, learner.best_checkpoint_file, device)\n",
    "    \n",
    "    test_preds = infer(learner.model, test_loader, learner.best_checkpoint_file, device)\n",
    "    preds += test_preds / folds.n_splits\n",
    "    \n",
    "    del learner\n",
    "    gc.collect()\n",
    "    \n",
    "print(f'OOF score: {spearmanr_np(oofs, y)}')\n",
    "#0.3982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipping is necessary or we will get an error\n",
    "sample_submission.loc[:, 'question_asker_intent_understanding':] = np.clip(preds, 0.00001, 0.999999)\n",
    "sample_submission.to_csv('subs/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.930843</td>\n",
       "      <td>0.607404</td>\n",
       "      <td>0.166507</td>\n",
       "      <td>0.440581</td>\n",
       "      <td>0.669049</td>\n",
       "      <td>0.547609</td>\n",
       "      <td>0.687640</td>\n",
       "      <td>0.663405</td>\n",
       "      <td>0.558132</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.646797</td>\n",
       "      <td>0.544287</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.090047</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.102497</td>\n",
       "      <td>0.170535</td>\n",
       "      <td>0.769937</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.898811</td>\n",
       "      <td>0.923496</td>\n",
       "      <td>0.536194</td>\n",
       "      <td>0.959436</td>\n",
       "      <td>0.968863</td>\n",
       "      <td>0.801682</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.031672</td>\n",
       "      <td>0.862513</td>\n",
       "      <td>0.921132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.868914</td>\n",
       "      <td>0.530974</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.732702</td>\n",
       "      <td>0.786088</td>\n",
       "      <td>0.927408</td>\n",
       "      <td>0.568578</td>\n",
       "      <td>0.503941</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.430015</td>\n",
       "      <td>0.065408</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.937538</td>\n",
       "      <td>0.183981</td>\n",
       "      <td>0.076124</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.645376</td>\n",
       "      <td>0.956150</td>\n",
       "      <td>0.650583</td>\n",
       "      <td>0.979844</td>\n",
       "      <td>0.988976</td>\n",
       "      <td>0.883237</td>\n",
       "      <td>0.951957</td>\n",
       "      <td>0.101983</td>\n",
       "      <td>0.050922</td>\n",
       "      <td>0.915610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.902329</td>\n",
       "      <td>0.604063</td>\n",
       "      <td>0.025335</td>\n",
       "      <td>0.733137</td>\n",
       "      <td>0.777548</td>\n",
       "      <td>0.903211</td>\n",
       "      <td>0.588324</td>\n",
       "      <td>0.498472</td>\n",
       "      <td>0.067626</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.433295</td>\n",
       "      <td>0.148209</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>0.019243</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.308063</td>\n",
       "      <td>0.096844</td>\n",
       "      <td>0.748049</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.828392</td>\n",
       "      <td>0.927451</td>\n",
       "      <td>0.594645</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.973351</td>\n",
       "      <td>0.812643</td>\n",
       "      <td>0.050541</td>\n",
       "      <td>0.040061</td>\n",
       "      <td>0.915093</td>\n",
       "      <td>0.927134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.915020</td>\n",
       "      <td>0.387382</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.671688</td>\n",
       "      <td>0.714732</td>\n",
       "      <td>0.856546</td>\n",
       "      <td>0.589083</td>\n",
       "      <td>0.486069</td>\n",
       "      <td>0.285419</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>0.610737</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.922026</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>0.331883</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.719859</td>\n",
       "      <td>0.947270</td>\n",
       "      <td>0.698330</td>\n",
       "      <td>0.975601</td>\n",
       "      <td>0.981805</td>\n",
       "      <td>0.875762</td>\n",
       "      <td>0.696216</td>\n",
       "      <td>0.166520</td>\n",
       "      <td>0.834448</td>\n",
       "      <td>0.925470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.962328</td>\n",
       "      <td>0.611163</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.890432</td>\n",
       "      <td>0.850477</td>\n",
       "      <td>0.930194</td>\n",
       "      <td>0.666699</td>\n",
       "      <td>0.658756</td>\n",
       "      <td>0.174202</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>0.290648</td>\n",
       "      <td>0.417940</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.017495</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.035297</td>\n",
       "      <td>0.194250</td>\n",
       "      <td>0.125485</td>\n",
       "      <td>0.474603</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.812403</td>\n",
       "      <td>0.908796</td>\n",
       "      <td>0.629941</td>\n",
       "      <td>0.960132</td>\n",
       "      <td>0.956322</td>\n",
       "      <td>0.820174</td>\n",
       "      <td>0.113894</td>\n",
       "      <td>0.120473</td>\n",
       "      <td>0.562951</td>\n",
       "      <td>0.909372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.930843                0.607404   \n",
       "1     46                             0.868914                0.530974   \n",
       "2     70                             0.902329                0.604063   \n",
       "3    132                             0.915020                0.387382   \n",
       "4    200                             0.962328                0.611163   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.166507                      0.440581   \n",
       "1                 0.002086                      0.732702   \n",
       "2                 0.025335                      0.733137   \n",
       "3                 0.003063                      0.671688   \n",
       "4                 0.012648                      0.890432   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.669049                               0.547609   \n",
       "1               0.786088                               0.927408   \n",
       "2               0.777548                               0.903211   \n",
       "3               0.714732                               0.856546   \n",
       "4               0.850477                               0.930194   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.687640                       0.663405   \n",
       "1                         0.568578                       0.503941   \n",
       "2                         0.588324                       0.498472   \n",
       "3                         0.589083                       0.486069   \n",
       "4                         0.666699                       0.658756   \n",
       "\n",
       "   question_multi_intent  question_not_really_a_question  \\\n",
       "0               0.558132                        0.002537   \n",
       "1               0.019184                        0.005083   \n",
       "2               0.067626                        0.011130   \n",
       "3               0.285419                        0.002294   \n",
       "4               0.174202                        0.007387   \n",
       "\n",
       "   question_opinion_seeking  question_type_choice  question_type_compare  \\\n",
       "0                  0.646797              0.544287               0.012849   \n",
       "1                  0.430015              0.065408               0.001647   \n",
       "2                  0.433295              0.148209               0.013836   \n",
       "3                  0.610737              0.051019               0.001037   \n",
       "4                  0.290648              0.417940               0.007290   \n",
       "\n",
       "   question_type_consequence  question_type_definition  question_type_entity  \\\n",
       "0                   0.090047                  0.007879              0.008882   \n",
       "1                   0.000403                  0.000374              0.002225   \n",
       "2                   0.019243                  0.003444              0.004389   \n",
       "3                   0.000585                  0.000408              0.025507   \n",
       "4                   0.017495                  0.003930              0.035297   \n",
       "\n",
       "   question_type_instructions  question_type_procedure  \\\n",
       "0                    0.102497                 0.170535   \n",
       "1                    0.937538                 0.183981   \n",
       "2                    0.308063                 0.096844   \n",
       "3                    0.922026                 0.244529   \n",
       "4                    0.194250                 0.125485   \n",
       "\n",
       "   question_type_reason_explanation  question_type_spelling  \\\n",
       "0                          0.769937                0.001328   \n",
       "1                          0.076124                0.000210   \n",
       "2                          0.748049                0.001992   \n",
       "3                          0.331883                0.000173   \n",
       "4                          0.474603                0.002255   \n",
       "\n",
       "   question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0               0.898811        0.923496                     0.536194   \n",
       "1               0.645376        0.956150                     0.650583   \n",
       "2               0.828392        0.927451                     0.594645   \n",
       "3               0.719859        0.947270                     0.698330   \n",
       "4               0.812403        0.908796                     0.629941   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          0.959436          0.968863             0.801682   \n",
       "1          0.979844          0.988976             0.883237   \n",
       "2          0.973653          0.973351             0.812643   \n",
       "3          0.975601          0.981805             0.875762   \n",
       "4          0.960132          0.956322             0.820174   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                  0.006590               0.031672   \n",
       "1                  0.951957               0.101983   \n",
       "2                  0.050541               0.040061   \n",
       "3                  0.696216               0.166520   \n",
       "4                  0.113894               0.120473   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.862513             0.921132  \n",
       "1                        0.050922             0.915610  \n",
       "2                        0.915093             0.927134  \n",
       "3                        0.834448             0.925470  \n",
       "4                        0.562951             0.909372  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
